[{"title":"Git Review Memo","date":"2021-03-21T06:00:00.000Z","path":"posts/60954/","text":"本文为Pro Git阅读笔记，整理了日常操作中涉及到的git操作。 Basic git xxx -h 可以查看该命令参数的简要介绍 git help xxx可以查看详细文档 命令中--用来区分参数和文件路径(e.g. git checkout -- &lt;file&gt;) 撤销更改 git commit --amend [--no-edit] 将内容增加进上次的更改[保持提交信息不变] git restore --staged &lt;file&gt; git reset HEAD &lt;file&gt; 撤销文件暂存 git restore &lt;file&gt; git checkout -- &lt;file&gt; 撤销文件的编辑(不可恢复) git revert 创建一个新的commit来撤销指定的commit 撤销合并见下文 分支操作 git内部是一个单向列表，每个节点的指针都指向前一个节点。每个 branch 都是一个指针, HEAD 也是一个指针只想当前 checkout 出来的位置这非常重要! 理解这一点就能理解下面的一切了 use git switch to switch git branch [--merged | --no-merged] [&lt;name&gt;] 显示已经合并(或没有合并)进当前分支(或name分支)的分支 git branch &lt;name&gt; [&lt;hash&gt;] 从当前状态[使用指定hash]创建分支 git branch -d &lt;name&gt; 删除指定分支(-D强制删除) git checkout -b &lt;name&gt; [&lt;hash&gt;] 创建并切换分支 关于合并分支与分叉 当两个分支都进行了各自的更改并commit后才会有所谓分叉现象，会使用 3-way merge策略 进行合并 如果只是一个分支有更改而另一个分支没有，则合并使用简单的 fast-forward 策略合并即可 fast-forward 当试图合并两个分支时，如果顺着一个分支走下去能够到达另一个分支，那么Git只会简单的将指针向前推进（指针右移） 遇到冲突的情况 ======符号的上半部分为HEAD所指的文件状态，也就是当前检出的分支的文件状态，下半部分为传入的更改 在处理好冲突后，使用git add将其标记为处理完成 git mergetool可以启动图形化界面帮助处理更改 全部处理完成后使用git commit来进行提交 Merge, rebase and squazemergemerge会将待合并分支的信息全部带入到合并结果中。 问题：如果一个节点有两个前向节点怎么存储？ remote-branch git fetch 可以将服务器的数据拉取到本地来，但是并不修改本地的分支 git branch -vv 可以查看分支追踪情况 git ls-remote 显示远程情况 git checkout -b &lt;name&gt; &lt;remote/name&gt;可以从一个远程分支创建本地分支来开始工作，这会自动创建所谓追踪分支 git push --set-upstream-to &lt;local_bantch_name&gt;[:&lt;remote_bantch_name&gt;]可以将本地存在而远程不存在的分支推送到远程去，同样自动追踪 这等价于下面两步操作 step1 git push &lt;origin&gt; &lt;local_bantch_name&gt;[:&lt;remote_bantch_name&gt;] 将本地的某个分支推送到远程 step2 git branch [-u | --set-upstream-to] &lt;origin/xxx&gt;将本地的追踪分支设定为远程的xxx git push origin --delete xxx可以删除远程分支xxx git push origin :&lt;NAME&gt; 效果同样 关于追踪分支 git checkout --track origin/serverfix 也可以从远程创建追踪分支 git checkout serverfix当本地不存在远程存在时，这样子会自动按照上一条执行 git checkout -b &lt;name&gt; &lt;remote/name&gt; 可以创建和远程名称不同的本地分支 RebaseRebase 是把相对于共同祖先节点的操作整理出来依次应用到目标分支，以此来达到消除分叉的目的。 Rebase后只是checkout到目标分支进行fast-forward merge git rebase &lt;target_branch&gt;把当前分支应用到 target_branch 上 git rebase --onto master server client 将在client分支里但不在server分支里的修改后合并到master上 git rebase &lt;basebranch&gt; &lt;topicbranch&gt; 把topic整合到base上 技巧 如果本地和远程都有修改可以直接rebase本地到remotes/origin/HEAD 选择或指定commit git show &lt;hash&gt; 用来查看指定提交 HEAD@&#123;n&#125; HEAD第n次移动前的位置(当前为0) git reflog可以查看历史记录 同理main@&#123;3&#125;可以查看main3次移动前的位置 引用日志只保存在本地 HEAD^[n] 代表HEAD的第n个父提交(不写n代表1) 用于选择在合并分叉的时候造成的多个父亲 HEAD~[n] 节点[的父亲]*n 用来选择祖父节点 git log master..topic topic分支中有但是master分支中没有的提交 git diff master..topic 查看两个分支的差别 git log refA refB ^refC refA和refB中有但是refC中没有的提交 git log [--left-right] master...experiment 被两者之一包含但是不被同时包含的提交[显示究竟被哪个包含] 交互式操作 git add -i 进入交互式暂存模式，可以把文件的一部分更改add进去 类似的还有下面几个(-p —patch)： git add -p git stash -p git restore -S -p 交互式取消stage git restore [-s] -p 交互式discard(取消更改) 修改提交历史 git rebase -i HEAD~3 交互式的rebase即可完成修改 关于reset和checkout文档链接 基本概念 文档中所说的Index是指暂存区(看图理解) Git将上一次检出到工作目录中的所有文件填充到索引区 之后你会修改并使用git add将其中一些文件替换为新版本 接着通过 git commit 将它们转换为树来用作新的提交 Working Tree就是指工作目录 reset和checkout的区别git checkout是在移动HEAD自己，而reset是移动HEAD所指向分支的指向 两者的使用 commit级别 --soft 只改变HEAD，不改变Index和Working Tree。本质上是撤销git commit。这样进行commit相当于在进行git commit -amend --mixed 改变HEAD和Index，不改变Working Tree。相当于在上面的基础上再进行git restore -S --hard 全都改变。相当于在上谜案的基础上再进行git restore -s(危险) 操作单个文件 git reset [commit] &lt;paths&gt; 使某个文件在Index中的状态变到指定版本 git checkout [commit] &lt;paths&gt;使某个文件在Working Tree中的状态变到指定版本(危险) 撤销合并 git reset --hard HEAD~ 但是这会修改历史，如果已经发布更改最好不这样做 git revert -m 1 HEAD -m指出回到哪个父节点，对于合并来说1就是刚刚合并来的那个节点 不甚严谨的几点理解git主要包括节点和指针，数据和文件目录会以节点的形式存储起来，而branch, HEAD等均为指向节点的指针。 commit和add操作是在创建节点，其他操作几乎都是在移动指针 git push是在移动仓库的指针remotes/origin/HEAD等等 git pull是在依据设定的”追踪分支”尝试merge远程更改并移动HEAD指针及分支指针 git merge rebase等是在比对文件并移动HEAD和HEAD所指向的branch的指针 reset是在试图直接操作指针和Index区域， 在各种指针移动的时候对应的节点并不会被删除，只是因为链接为单项的，可能指针的移动而无法找到，但是只要能找到那个节点hash就可以恢复(e.g. 使用reflog)。换句话说，理论上只要git已经为文件创建了blob文件，那么内容就不会丢失只是可能不容易找到。 参考资料: 全文内容为Pro Git阅读笔记","tags":[{"name":"git","slug":"git","permalink":"https://blog.yrpang.com/tags/git/"}]},{"title":"创建Apple设备描述文件并签名","date":"2020-11-15T04:33:06.000Z","path":"posts/6894/","text":"Apple开发者上大会宣布可以在macOS11.0和iOS14以上的设备上设置DoH和DoT，但是只支持用设备描述文件的方式来进行配置，这两天好奇了一下，这篇文章记录一下关于设备描述文件的资料以及给配置文件的签名的方法。 创建设备描述文件所谓设备描述文件就是一个xml格式的文档，里面记录了各个配置项的值，具体内容参照下面的官方文档即可。 概括性说明 Apple Developer Document: Configuring Multiple Devices Using Profiles 具体配置项文档 Profile-Specific Payload Keys 文件所需的Payload UUID可以使用uuidgen生成，相同id的描述文件重复安装会覆盖。 描述文件的签名将上一步骤的文件存储为.mobileconfig拓展名的文件就可以直接在设备上打开安装了，只不过这时候描述文件会显示为未验证或者不受信任，这让强迫症很难受，同时也没法确保文件在传输过程中不被篡改，所以我们要给文件加上电子签名。 首先要说明，这里苹果并不在意证书的用途，只验证证书信任链，所以对于我们没有注册成为开发者的人来说，可以用两种方法建立信任：一是使用Let&#39;s Encrypt等签发的域名证书，因为其根证书收到苹果信任，用这种方式签名的证书也会受到信任；二是建立自己的自签名根证书并导入设备，之后直接使用根证书签名或者使用根证书再签发证书建立自己的信任链。 考虑到Let&#39;s Encrypt的签发的证书有效期只有3个月，同时描述文件主要是用来给自己用或者是给组织内部使用，所以主要介绍使用自签名的方式建立信任，把借助SSL证书建立信任的方式放在最后。 这里还要说下，如果已经是苹果的开发者了，拥有苹果签发的开发者证书的话可以直接跳到最后“碎碎念”部分 使用自签名证书这里我们按照三级结构Root CA --&gt; Intermediate CA --&gt; Leaf CA的方式来建立。 整个步骤使用macOS自带的”钥匙串访问”和App Store下载的”Apple Configurator 2”即可轻松完成，当然也可以选用openssl来创建。 首先在钥匙串中使用证书助理创建证书颁发机构选择创建根证书，然后再次创建证书颁发机构，这次选择创建中间证书并且选择使用刚刚创建的根证书签名，最后点击创建证书使用中级证书签名，创建叶子证书。 将自己的根证书标记为受信任，并导出，导出类型选择.cer即可。 完成后将描述文件用”Apple Configurator 2”打开，选择”文件-&gt;签名”，选择上一步创建的叶子证书签名。 将步骤2导出的根证书在设备上打开，会自动创建包含证书的描述文件，选择安装就会将自己的根证书加入到受信任证书列表中了。 将签名后的描述文件发送给设备，在设备上打开，这时因为根证书收到信任，所以中间证书收到信任，所以叶子证书收到信任，如果签名校验没有错误的话就会显示描述文件受到信任了。 完成上面几个步骤后，对于个人来说我们可以把签名过的描述文件放到网上存储，用自己需要使用的设备访问下载，只要下载后的文件验证通过，就可以证明文件的确是自己的没有被篡改。对于组织来说可以把组织自己的Root CA预先配置在设备里面，只要描述文件签名验证通过就可以证明该文件确实为组织管理员所发布并且没有被篡改。 使用SSL证书进行签名这里因为域名证书的用途里面不包含代码签名，所以就算导入到钥匙串中，证书也不会出现在上述工具的可用证书列表里，所以我们只能使用openssl来完成。 以Let&#39;s Encrypt签发的证书为例，我们会得到fullchain.pem和privkey.pem两个文件，将他们scp到本地: fullchain.pem包含了发给我们域名的叶子证书以及用于建立信任链的中级证书 privkey.pem则是我们证书的私钥，特别注意这里的私钥是没有密码保护的，要特别注意安全 主要步骤: 把fullchain.pem中的叶子证书和中间证书分开保存，前面的部分为叶子证书(server.crt)，后面的为中间证书(ca.crt) 签名openssl smime -sign -in unsigned.mobileconfig -out signed.mobileconfig -signer server.crt -inkey server.key -certfile ca.crt -outform der -nodetach 完成后就可以将描述文件发布到网上供人下载了，因为Let&#39;s Encrypt的根证书本身是受到设备系统信任的，就不需要再导入根证书了。 碎碎念在苹果提供”Apple Configurator 2”工具之前，网上针对个人开发者证书的方法是：首先把个人开发者证书导出(.p12)，然后用openssl拆分成证书和私钥，因为格式不对还要转换格式(cer-&gt;crt)，然后再把Apple的中级证书下载下来合并到里面构建信任链最后再签名。 这个流程很繁琐，而且过程中先是把钥匙串中的私钥导出来，又把有密码保护的私钥直接暴露了出来，增加了安全风险，现在已经没有必要，对于有开发者证书的人来说直接按照“使用自签名证书”的步骤3选择自己的证书签名然后分发就可以了，节省时间同时也增加安全性。 关于如何把证书私钥导入到钥匙串这几天仔细研究了一下钥匙串，感觉把私钥放到钥匙串保存应该比我自己靠谱不少。但是发现直接双击.pem格式的私钥会提示项目已损坏无法取回导入失败，试验来看似乎只接受.p12格式: 将证书和私钥匙放在一起，对于Let&#39;s Encrypt签发的来说把server.key粘贴到fullchain.pem后面就可以了cat server.key &gt;&gt; fullchain.pem 使用openssl转换格式openssl pkcs12 -export -in fullchain.pem -out cer.p12 参考资料 Mobileconfig SSL签名 Over-the-air IPhone Setup Using a Signed .mobileconfig File","tags":[{"name":"Apple","slug":"Apple","permalink":"https://blog.yrpang.com/tags/Apple/"},{"name":"mobileconfig","slug":"mobileconfig","permalink":"https://blog.yrpang.com/tags/mobileconfig/"}]},{"title":"Wireshark Wi-Fi抓包","date":"2020-11-12T05:09:58.000Z","path":"posts/55555/","text":"最近这两天有点儿偏离主线了，稍微摆弄了一下之前去年这时候没弄懂咋用的WireShark，然后发现网上关于无线网络抓包的东西东一块西一块的，缺乏系统性整理，而且有些说法是错误的，所以写下这一篇粗浅的文章做一个简单整理和记录。 系统环境因为操作系统和网卡驱动可能会影响，所以贴一下实验环境： 电脑: MacBook Pro (13-inch, 2017, Four Thunderbolt 3 Ports)系统: MacOS 10.15.7 (19H15) 抓包条件在开始前先弄清Wireshark的两个模式选项: Promiscuous modeIn promiscuous mode the MAC address filter mentioned above is disabled and all packets of the currently joined 802.11 network (with a specific SSID and channel) are captured, just as in traditional Ethernet. However, on a “protected” network, packets from or to other hosts will not be able to be decrypted by the adapter, and will not be captured, so that promiscuous mode works the same as non-promiscuous mode. This seems to work on Linux and various BSDs, including Mac OS X. On Windows, putting 802.11 adapters into promiscuous mode is usually crippled, see the Windows section below. Monitor mode In monitor mode the SSID filter mentioned above is disabled and all packets of all SSID’s from the currently selected channel are captured. Even in promiscuous mode, an 802.11 adapter will only supply to the host packets of the SSID the adapter has joined, assuming promiscuous mode works at all; even if it “works”, it might only supply to the host the same packets that would be seen in non-promiscuous mode. Although it can receive, at the radio level, packets on other SSID’s, it will not forward them to the host. Therefore, in order to capture all traffic that the adapter can receive, the adapter must be put into “monitor mode”, sometimes called “rfmon mode”. In this mode, the driver will put the adapter in a mode where it will supply to the host packets from all service sets. Depending on the adapter and the driver, this might disassociate the adapter from the SSID, so that the machine will not be able to use that adapter for network traffic, or it might leave the adapter associated, so that it can still be used for network traffic. ——WLAN (IEEE 802.11) capture setup 混杂模式(Promiscuous)：让网卡把所有的包不管mac地址是不是发给自己的全都收进来 监视模式(Monitor Mode)：保留802.11原始头部，并且收指定信道（频率范围）能听到的所有信号，不管SSID是什么全都收进来 在我的设备上测试结果是混杂模式不起作用，MacOS只给两个选择要么就开Monitor Mode全都收进来，要么就只收自己的，所以就分两种情况讨论下： 先说抓自己本机的，这个很容易不需要特殊配置，只要打开Wireshark选中自己的Wi-Fi网卡开始抓包就可以了，就算是加密的Wi-Fi出来的内容也已经是解密好的。 再说抓别人的，上面说过在我的测试环境下”混杂模式”没有起到预期的作用，所以就直接勾选无线网卡的”监视模式”，勾选后Link-layer Header就会变成802.11 plus radiotap header了。然后开启抓包，这时如果你处在像宿舍这样的周围无线信号很嘈杂的环境的话就能一下子看到非常多的报文了。 选择指定的SSID选择Wireless-&gt;WLAN Traffic就可以打开Wireshark中的一个简单的无线网络分析工具，可以查看到Wireshark帮我们解析并统计出来的周围路由器以及和他们通信的设备，里面也包含了简要的通信量统计等信息。找到我们想要的路由器的SSID然后直接Apply as Filter就可以筛选出和这个路由器通信的包了。 如果你选择是一个没有密码的Wi-Fi，这时候就可以直接看到更上层的数据链路层报文了，如果恰好又有人在应用层使用HTTP通信的话那就可以直接看到内容，如果又恰好通信的内容也没有加密措施的话那就什么都能看到了。不过现在网站基本全都HTTPS了，应该基本是不存在这种情况了。 解密如果是加密的Wi-Fi的话那对于使用WPA2个人级别加密的Wi-Fi的话，解密负载内容需要两个条件 在Preferences-&gt;Protocols-&gt;IEEE 802.11中勾选Enable Decryption并且填上Wi-Fi的密码(格式：passwd:SSID) 抓取到设备连接时和路由器完整的四次握手，开始抓包后把手边的设备Wi-Fi断开然后重新连接下即可 满足这两个条件之后就可以和没有密码的Wi-Fi一样看到更上层的传输内容了。 WPA2企业级有看到说法似乎是不大行，不过这点没有求证，存疑。 其它工具 Wireshark的抓包结果和tcpdump -I下的结果一致 另外macOS在无限诊断工具中已经提供了抓包工具，按住option点Wi-Fi图标之后在窗口那里选择就好了，可以使用Wireshark分析抓取结果 最后记录一下我对一些说法的异议 第一个，对于无线网络来说，你选择了信道也就是频率范围，那么该频率下的所有包不管是发给你的还是不是发给你的，也不管是谁发出来的你都可以收到，只是你能不能解密出内容的区别。所以并不会因为Wi-Fi路由器给出来的AP隔离之类的选项导致不能抓到包。这和有线连接交换机的设置是不一样的，不需要端口镜像，更不用arp欺骗。 第二个，暂时忘了…想起来了再补… 有帮助的参考资料 Wireshark文档: WLAN (IEEE 802.11) capture setup","tags":[{"name":"安全","slug":"安全","permalink":"https://blog.yrpang.com/tags/%E5%AE%89%E5%85%A8/"},{"name":"WireShark","slug":"WireShark","permalink":"https://blog.yrpang.com/tags/WireShark/"}]},{"title":"浅谈SSL和GPG","date":"2020-11-09T06:35:15.000Z","path":"posts/23547/","text":"去年的这个时候因为想用GPG签名git提交学习了一下GPG的工作原理，还写了一篇博客简单记录。今年又是这个时候偶然看到了CloudFlare Blog 的一篇2015年的文章How to build your own public key infrastructure在讲如何构建自己的自签名SSL证书用于加密后端服务内部的相互通信，文章讲的炒鸡简洁清晰，感觉一下子对之前一直迷迷糊糊的SSL证书签署过程有了比较清晰的理解，和GPG密钥两相对照之下也加深了对GPG的理解，所以写下此文简要记录一下。 GPG和SSL的区别 Public key cryptography provides many mechanisms for trust, including PGP’s “web of trust” and HTTPS’s public key infrastructure (PKI) model. ——CloudFlare Blog 这两个背后对应的是两种不同的信任机制模型，一句话来说GPG的背后PGP模型是”信任你信任的人所信任的人”，而HTTPS背后的PKI模型则是”信任权威机构信任的人”。 这两种方式都可以简单可靠的建立直接信任，所谓直接信任是指使用者因为知道一把密钥从哪里来而信任它是有效的。简单的例子比如你和我当面交换公钥，然后之后我们在网络上使用自己私钥对内容进行签名，那么我们互相都可以证明对方收到的信息真的是由自己发出的并且没有被篡改。再比如软件仓库的维护者将公钥发布在使用了HTTPS的网站上，当我们下载了软件后就可以通过验证签名确认软件没有被篡改。 但是我们在生活中往往遇到的都是需要向完全陌生人证明自己是自己这样的情况，在这种情况下两者各有优缺点： PGP把信任机制的建立诉诸于社交网络式的结构而不是权威机构，带来的直观好处就是省下了权威机构认证的钱。坏处就是信任机制较弱，PGP可以帮助轻松的证明秘文没有被修改也可帮你完成信息的加密和解密，但是很难帮你向陌生人证明你(uid)就是你，虽然可以通过密钥被接收者也信任的人签名过来间接确认，但是信任机制的建立需要长时间慢慢积累来建立。 随着时间过去，你累积到许多人的密钥，其中有些人你也许愿意签署信赖他们，别人也会签署一些他们自己信赖的他人密钥。每个人都逐渐累积到一些他人已签署信赖的密钥，然后自己再签署并散发出去。那么便能期待，下一个拿到这把密钥的人在签署名单上总有一两个是自己信赖的。这最终能形成所有公钥的分布式防弊的信赖网络。 ——PGP的发明者 菲利普·齐默曼 和PGP相反，PKI模型则是把信任的建立诉诸权威机构，通过权威机构逐级签署密钥的方式来建立信任，HTTPS正是采用这种方式。这样建立信任比较简单，只要将几个知名CA的证书在操作系统中就预先标记为受信任，那么由他们的私钥直接签署的证书或者由他们签署的中间级证书对应的私钥签署的证书都可以被标记为受到信任，这样的签署机制逐层传递下去就可以很轻松的使得证书的拥有者证明自己就是自己。但是正是因为信任的建立和身份的真实性的鉴别都依赖权威机构，所以证书的申请者需要为此付费，这也导致HTTPS最初推广进展缓慢，直到Let’s Encrypt 之类的免费证书签发机构的出现才改善了状况。 SSL证书是如何被签署的？要想清楚了解SSL证书的签署过程，首先要先搞清楚过程中需要的几个文件： 证书：所谓证书就是一个包含拥有者信息、公钥、CA签名的一个文件 私钥：每个证书都对应一个私钥可以用来签名或者加密 CSR(certificate signing request)：包含CA签名证书所需信息的文件，我们需要把这个提交给CA来签名我们的证书，主要包括几部分 申请者的信息 待签名证书的公钥 用自己的私钥产生的签名 在得到CSR后CA就可以开始签署过程： 首先使用公钥验证CSR的签名，确保请求没有被篡改 按照审核规则检查申请者的信息，审核信息是否真实并判断是不是可以通过(典型的手段包括验证DNS记录和HTTP验证等方式) 使用CA自己的私钥创建并签名证书，并把证书发回申请者，整个过程结束 需要注意的是因为对于CA来说被预先内置在操作系统中分发的证书(根证书)极为重要，相应的私钥一旦丢失就意味着信任机制的完全破坏几乎无法恢复，所以在操作中并不使用”根证书”的私钥签署，而是先用其签署一份”中级证书”之后就离线保存起来，之后使用Intermediate 证书来进行签署，这样万一真的发生泄漏只要将中级证书吊销，根证书的信任仍然可以不受破坏。 此外对于Let’s Encrypt 这样的较新的颁发机构来说，为了确保自己的证书可以被更多的浏览器信任，会使用多个已被广受信任的根证书来进行交叉签名。关于这一点的详细的描述见 Let’s Encrypt: Chain of Trust。 CA是如何建立的？建立CA并不难，主要包括三步： 创建根证书 创建中间证书并使用根证书签名，完成后将根证书离线安全保存 按照一定规则审核申请并使用中间证书签发证书 但是要想让自己的证书广受信任就得把自己的根证书在操作系统中标记为信任，在不打扰用户的情况下这对我们来说是不可能完成的任务，所以使用自签发证书让用户的浏览器自动显示小绿锁是没有办法做到的。但是像文章开头说的那样建立自己的CA用于加密后端服务内部的相互通信是简单可行的，参照How to build your own public key infrastructure就可以了。 GnuPG使用备忘-s, --sign 生成一份签名 --clear-sign 生成一份明文签名 -b, --detach-sign 生成一份分离的签名 -e, --encrypt 加密数据 -d, --decrypt 解密数据（默认） --verify 验证签名 其它使用见之前的文章浅谈GPG 工具网站： crt.sh 用来查询证书状态 certbot 用来申请证书的客户端工具 参考资料： How to build your own public key infrastructure 信任网络，PGP，GPG","tags":[{"name":"GPG","slug":"GPG","permalink":"https://blog.yrpang.com/tags/GPG/"},{"name":"SSL","slug":"SSL","permalink":"https://blog.yrpang.com/tags/SSL/"}]},{"title":"proc文件系统","date":"2020-11-07T09:30:38.000Z","path":"posts/52529/","text":"记录一些确定Linux系统状态定位问题的的指令。 是什么？ The proc filesystem is a pseudo-filesystem which provides an interfaceto kernel data structures. It is commonly mounted at /proc. from Linux Manual 通过proc文件系统可以查看有关系统硬件及当前正在运行进程的信息，也可以通过更改其中某些文件来改变内核的运行状态。很多常用的工具(e.g. top、free)都是通过访问proc中的信息来工作的。 proc下的一些文件： /proc/apm高级电源管理（APM）版本信息及电池相关状态信息(当编译的时候CONFIG_APM为启用时才有效) /proc/buddyinfo用于诊断内存碎片问题的相关信息文件 /proc/interrupts对于每个CPU的中断号以及中断次数 /proc/loadavg关于CPU和磁盘I/O的负载平均值 ➜ ~ cat /proc/loadavg 0.63 0.77 0.85 1/156 6536 | | | | | | | | | | | | | | | | | |__最近一个由内核创建的进程的PID | | | | |_______系统当前存活的内核调度实体的数目 | | | |__________正由内核调度的实体（进程和线程）的数目 | | |_____________每15秒钟 | |__________________每5秒钟 |_______________________每1秒钟 关于文件信息: 文件内的信息计算公式如下 /proc/uptime系统上次启动以来的运行时间，第一个数字表示系统运行时间，第二个数字表示系统空闲时间，单位是秒。 uptime其实访问这两个文件 ➜ ~ uptime 19:11:47 up 42 days, 3:30, 2 users, load average: 0.73, 0.86, 0.88 /proc/meminfo当前内存的利用状况等的信息，free访问的就是这个 /proc/modules当前装入内核的所有模块名称列表，由lsmod命令使用 /proc/swaps系统上的交换分区及其空间利用信息 /proc/zoneinfo内存区域（zone）的详细信息列表 /proc/slabinfo内存频繁使用的对象的cache（应该大体可以理解为系统占用的部分），该文件列出了这些对象相关slap的信息 /proc/stat系统的一些运行信息，不同体系结构会不一样 /proc/vmstat系统虚拟内存的多种统计数据 等等其它似乎用到的不多 进程下面的东西proc/[num]都系统进程的pid对应的状态文件，目录结构较为固定： cmdline启动当前进程的完整命令 fd目录包含当前进程打开的每一个文件的文件描述符（file descriptor） limits当前进程所使用的每一个受限资源的软限制、硬限制和管理单元 root指向当前进程运行根目录的符号链接 stat当前进程的状态信息 statm进程占用内存的状态信息 status与stat所提供信息类似，但可读性较好 task当前进程所运行的每一个线程的相关信息 参考资料： ecs运维指南-Linux 系统诊断[公众号：程序猿石头]","tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.yrpang.com/tags/Linux/"}]},{"title":"HTTPS相关","date":"2020-11-07T08:05:00.000Z","path":"posts/46833/","text":"HTTPS不加密什么？对于TLS1.3以前的来说URL和客户端IP是不加密的。 为什么不加密URL为了支持SNI。 如何解决？TLS1.3引入了”encrypted SNI”来解决这个问题。 工具 SSL配置测试 SSL Configuration Generator 参考资料 StackOverflow: Are HTTPS URLs encrypted? Introduction to HTTPS Encrypt it or lose it: how encrypted SNI works","tags":[{"name":"安全","slug":"安全","permalink":"https://blog.yrpang.com/tags/%E5%AE%89%E5%85%A8/"}]},{"title":"dig和host工具","date":"2020-11-07T06:08:52.000Z","path":"posts/62128/","text":"简单记录一下DNS查询的工具 dig工具的使用dig [@global-server] [domain] [q-type] [q-class] &#123;q-opt&#125; &#123;global-d-opt&#125; q-type NS 记录：用来指定域名由哪个 DNS 服务器进行解析； CNAME 记录：用来定义域名的别名，方便实现将多个域名解析到同一个 IP 地址； A 记录：用来指定主机名对应的 IPv4 地址； AAAA 记录：用来指定主机名对应的 IPv4 地址； MX 记录：用来指定收件人域名的邮件服务器，SMTP 协议会根据 MX 记录的值来决定邮件的路由过程； PTR 记录：常用于反向地址解析，将 IP 地址解析到对应的名称； SOA 记录：称为起始授权机构记录，不同于 NS 记录用于标识多台域名解析服务器，SOA 记录用于在多台 NS 记录中哪一台是主 DNS 服务器。 常用q-opt -x 反向查询 -p 指定 DNS 查询使用的端口号，默认情况下 DNS 查询使用标准的53端口 -4 指定 dig 命令仅使用 IPv4 查询传输 -6 指定 dig 命令仅使用 IPv6 查询传输 常用d-opt +short 直接显示查询结果，没有返回空 +trace 从根域名服务器开始递归式的查询并显示过程 结果返回SOA？ 当查询的类型不存在时会在“AUTHORITY SECTION”返回SOA记录 查询的域名不存在时，会在“AUTHORITY SECTION”返回其上一层（有可能更上层，直到根）的zone的SOA记录 host工具使用方法： host [url] 可以把解析记录用描述性的语言呈现出来清晰易懂。 参考资料 dig 命令洞察 DNS 解析过程 dns：逆向查询、查询返回SOA记录","tags":[{"name":"DNS","slug":"DNS","permalink":"https://blog.yrpang.com/tags/DNS/"},{"name":"后端","slug":"后端","permalink":"https://blog.yrpang.com/tags/%E5%90%8E%E7%AB%AF/"}]},{"title":"使用ethtool永久修改网卡MAC地址","date":"2020-11-03T06:38:04.000Z","path":"posts/20682/","text":"偶然看到一篇文章在谈如何使用ethtool永久修改MAC地址，这里所谓的永久修改是指直接刷写进网卡的EEPROM，第一次见到这样子的操作，不知道是不是所有网卡都可以，手边也暂时没设备可以测试，先mark一下。 原文：How to permanently change a MAC address using ethtool 先引述原作者的警告，修改错误可能会变砖，在修改前一定要记得备份！ !! CAUTION !! Writing to the EEPROM of the network device could brick the device. Before you actually write to the EEPROM, you should backup the original EEPROM TL;DR 备份：$ ethtool -e eth0 raw on &gt; eeprom-backup.bin 写入：$ ethtool -E eth0 magic &lt;N&gt; offset &lt;N&gt; value &lt;N&gt; 详细步骤及内容请参阅作者原文以及ethtool的manual。","tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.yrpang.com/tags/Linux/"}]},{"title":"vim速查表","date":"2020-10-15T09:40:09.000Z","path":"posts/40855/","text":"operator 按键 作用 x 删除一个字母 d 删除 dd 删除一行 u 撤销 U 撤销整行 Ctrl+R 重做 p 粘贴 r 替换 ce 更改 motion 按键 作用 w 下一个单词起始位置 e 单词末尾 $ 行末 注: num+motion可以重复执行。e.g. 2dd会删除两行 跳转类 按键 作用 (num)+G (前往第num行)或行尾 gg 首行 :(num) 前往第num行 查找类 按键 作用 / 向前查找 ? 向后查找 % 找配对括号 替换类 按键 作用 :s/old/new 替换一处 :s/old/new/g 替换一行里的所有 :#,#s/old/new/g 替换#行和#行之间的 :%s/old/new/g 替换文件里的所有 :%s/old/new/gc 交互式替换(每一个都问下要不要换) 其它 按键 作用 :Ctrl+D 自动补全命令 :!命令 执行命令 :w+名字 另存为 r 提取文件/输出 o 打开新一行 插入类 按键 作用 a 光标后插入 i 光标处插入 A 行末插入","tags":[{"name":"速查表","slug":"速查表","permalink":"https://blog.yrpang.com/tags/%E9%80%9F%E6%9F%A5%E8%A1%A8/"}]},{"title":"iptables笔记","date":"2020-10-05T12:09:51.000Z","path":"posts/44305/","text":"几个概念关于Netfilter首先防火墙的实现是基于Linux内核中的Netfilter模块的，该框架在网络数据包处理的五个节点（如下表）插入hook函数进而干预ip数据包的转发处理过程。 节点 作用 PREROUTING 路由判断之前的阶段 INPUT 路由判断后如果是自己的则进入该节点 FORWARD 路由判断后如果是不是自己的包则进入该节点 OUTPUT 上层处理完毕后返回处理结果发出去时经过的节点 POSTROUTING INPUT和FORWARD都会经过的节点 关于iptablesiptables是运行在用户空间的用来管理和配置Netfilter的软件。 iptables网站 关于dfw和firewalld两者是基于iptables或者nftables的管理软件，用于更方便的进行配置管理，具体不同发行版有所差异。 iptables的结构iptables包含四表五链，每个表包含几种链，关于表和链的更多讲解。 四表的优先级为raw–&gt;mangle–&gt;nat–&gt;filter。 raw包含PREROUTING和POSTROUTING不常用略去。 mangle默认五条链都包括，用于修改数据包 filter用于处理过滤过程，主要包含三条链 INPUT 链：过滤所有目标地址是本机的数据包 FORWARD 链：过滤所有路过本机的数据包 OUTPUT 链：过滤所有由本机产生的数据包 nat处理网络地址转换，可以进行 Snat（改变数据包的源地址）、Dnat（改变数据包的目标地址） PREROUTING 链：可以在数据包到达防火墙时改变目标地址 OUTPUT 链：可以改变本地产生的数据包的目标地址 POSTROUTING 链：在数据包离开防火墙时改变数据包的源地址 一般处理流程： 数据包进入的时候，先进 mangle 表的 PREROUTING 链。在这里可以根据需要，改变数据包头内容之后，进入 nat 表的 PREROUTING 链，在这里可以根据需要做 Dnat，也就是目标地址转换。 进入路由判断，判断是进入本地的还是转发的。 如果是进入本地的，就进入 INPUT 链，之后按条件过滤限制进入。 之后进入本机，再进入 OUTPUT 链，按条件过滤限制出去，离开本地。 如果是转发就进入 FORWARD 链，根据条件过滤限制转发。 之后进入 POSTROUTING 链，这里可以做 Snat，离开网络接口。 参考资料 1 Compare: Firewalld / Iptables / Nftables / Netfilter","tags":[{"name":"后端","slug":"后端","permalink":"https://blog.yrpang.com/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.yrpang.com/tags/Linux/"}]},{"title":"Pandas速查表","date":"2020-08-30T08:25:23.000Z","path":"posts/5186/","text":"基本数据结构操作 维数 名称 描述 1 Series 带标签的一维同构数组 2 DataFrame 带标签的，大小可变的，二维异构表格 DataFrame 是 Series 的容器，Series 则是标量的容器。使用这种方式，可以在容器中以字典的形式插入或删除对象。 df的基本操作 df[col]这样子取得的是列 df = pd.DataFrame(np.random.randn(6, 4), index=dates, columns=list(&#39;ABCD&#39;)) df.head(2) df.tail(3) df.index df.column df.to_numpy()可以转换为numpy df.describe()可以查看统计信息 df.T转置 df.sort_index(axis=1, ascending=False)按轴排序 df.sort_values(by=&#39;B&#39;) 选择数据 df[&#39;A&#39;]选择单列 df[0:3]切片行 按照标签选择df.loc[]选择一行 df.loc[:, [&#39;A&#39;, &#39;B&#39;]]选择多个列 选择范围就是组合应用上面的过程 df.at[]访问数据和上面的结果一样 df.iloc[]按照索引选择数据 布尔索引df[df.A &gt; 0] e.g.操作示范 for col in df.columns: series = df[col] # do something with series 显示控制#显示所有的列 pd.set_option(&#x27;display.max_columns&#x27;, None) #显示所有的行 pd.set_option(&#x27;display.max_rows&#x27;, None) #设置value的显示长度为100，默认为50 pd.set_option(&#x27;max_colwidth&#x27;,100) 常用操作1. 分组去重复统计 df.groupby(&#39;param&#39;)[&#39;group&#39;].nunique() 2. 去重data.drop_duplicates(subset=[&#39;A&#39;,&#39;B&#39;],keep=&#39;first&#39;,inplace=True) 3. 按日期字段分组import pandas as pd data = pd.read_csv(&#x27;xxx.csv&#x27;) data[&#x27;index&#x27;] = pd.to_datetime(data[&#x27;index&#x27;]) print(data.groupby([data[&#x27;index&#x27;].dt.year, data[&#x27;index&#x27;].dt.month]).mean()) print(data.groupby([data[&#x27;index&#x27;].dt.year, data[&#x27;index&#x27;].dt.month]).last()) 4. PANDAS 数据合并与重塑5. 使用自定义函数处理数据def equal_word(B,A): # A -&gt;关键词 B-&gt;品牌词 A,B=str(A),str(B) if B in A : return False #如果包含，返回False else: return True #如果不包含，则返回True df2=df1[[&#x27;S_key_word&#x27;,&#x27;S_brand&#x27;]] df1[&#x27;bool&#x27;]=df2.apply(lambda x :equal_word(x[&#x27;S_brand&#x27;] ,x[&#x27;S_key_word&#x27;]),axis=1)","tags":[{"name":"pandas","slug":"pandas","permalink":"https://blog.yrpang.com/tags/pandas/"}]},{"title":"解决网易163邮箱`Unsafe Login.`错误","date":"2020-05-28T04:31:45.000Z","path":"posts/45207/","text":"在尝试使用IMAP协议连接网易163邮箱后尝试读取收件箱时服务器返回Unsafe Login. Please contact kefu@188.com for help报错。 网上广为流传的解决方案是使用神秘网址http://config.mail.163.com/settings/imap/index.jsp?uid=xxxxxx@163.com进行设置。经过测试该方法已经失效了，不必再做尝试。 解决方案经过邮件询问报错原因是发送请求时没有包含imap id，回复如下： 关于您反馈的客户端问题，经核实，关于您反馈的客户端添加网易邮箱帐号出现的收信问题，经反馈核实是第三方客户端没有带imap id被判断为不安全登录，系统为了用户安全自动阻止该类登录。 IMAP ID是在RFC2971中定义的一个扩展IMAP指令，详情查阅该文档 对于我程序所使用的python imapcilent库来说，在login之后select文件夹之前使用文档中所述的id_方法向服务器发送ID命令客户端信息即可，文档链接 demofrom imapclient import IMAPClient server = IMAPClient(&quot;imap.163.com&quot;, ssl=True, port=993) server.login(&quot;&lt;user&gt;&quot;, &quot;&lt;passwd&gt;&quot;) server.id_(&#123;&quot;name&quot;: &quot;IMAPClient&quot;, &quot;version&quot;: &quot;2.1.0&quot;&#125;) messages = server.select_folder(&#x27;INBOX&#x27;) 一些碎碎念从定义来看这个ID扩展只是客户端对自己身份的单方面声明而已，根本没有办法进行任何验证，不大能理解为什么要把不带这一字段的判断为不安全，另外在RFC2971的3. Specification中对于用途也有下面的说明： The sole purpose of the ID extension is to enable clients and serversto exchange information on their implementations for the purposes ofstatistical analysis and problem determination. 以及 Servers MUST NOT deny access to or refuse service for a clientbased on information from the ID command. Clients MUST NOT refuseto operate or limit their operation with a server based on the IDresponse.","tags":[{"name":"IMAP","slug":"IMAP","permalink":"https://blog.yrpang.com/tags/IMAP/"}]},{"title":"Outlook和163邮箱IMAP、SMTP踩坑","date":"2020-05-13T15:13:52.000Z","path":"posts/55107/","text":"为了收作业想弄个自动收邮件+下载附件的东西放到阿里云Serverless上跑，邮箱选择的是Outlook，配置IMAP登录的时候遇到几个问题记录一下。 环境：python3.7 Microsoft 365 Outlook Outlook IMAP login fail没有任何其他错误返回，就是login faild，迷惑好久，网上的各种资料都说不到点子上。最后意识到是两步验证的问题，创建应用密码可以解决 说明文档：对不支持双重验证的应用使用应用密码 Outlook SMTP 发信失败Failed to process message due to a permanent exception with message Recipientisn\\&#39;t resolved 收件人部分不要使用utf-8编码即可解决 迷惑的163NO SELECT Unsafe Login. Please contact kefu@188.com for help Outlook的login faild是在太让人迷惑以至于我尝试了一下163，发现结果更加扯淡，我尝试联系了kefu@188.com至今未果，不过意外发现网易账号支持注销了emmmm 注销地址：网易账号中心 点击注销照着操作就行 update: 发完邮件就给忘了，今天打开邮箱发现收到回复了，感谢客服的及时回复，解决方案见这篇文章 如何建立starttls连接outlook的smtp服务器使用的是starttls连接，使用python标准库建立连接的方法如下。 sender = smtplib.SMTP(&#x27;outlook.office365.com&#x27;, 587) sender.starttls() sender.login(&quot;&lt;user&gt;&quot;, &quot;&lt;passwd&gt;&quot;) 关于邮件处理脚本目前是基于阿里云Serverless+OSS做的，异常处理还不够完善，也没有友好的收集进度显示，近期找时间完善下再放出来，到时也欢迎有需求的课代表们体验。记得Star（逃。","tags":[{"name":"Serverless","slug":"Serverless","permalink":"https://blog.yrpang.com/tags/Serverless/"}]},{"title":"torch.nn.function的一些参数","date":"2020-04-12T14:30:15.000Z","path":"posts/54034/","text":"本文用于随手记录我在学习ML的过程中用到的Pytorch函数中参数的含义和一些注意。 1 Conv2d这个要注意的它的padding是双向的，也就是补2倍的0","tags":[{"name":"Pytorch","slug":"Pytorch","permalink":"https://blog.yrpang.com/tags/Pytorch/"}]},{"title":"正则表达式","date":"2020-02-02T03:46:34.000Z","path":"posts/46563/","text":"简单记录正则表达式常用内容 源字符 源字符 含义 . 除换行符以外的任意字符 \\w 字母、数字、下划线、汉字 \\s 任意空白字符 \\d 任意数字 \\b 单词的开始或结束 ^ 字符串开始 $ 字符串结束 控制重复 控制符号 含义 * 任意次 + >=1次 ? 0/1次 {n} n次 {n,} >=n次 {n,m} n~m次 小工具pcretest pcre提供的一个小工，用来测试正则表达式 brew install pcre","tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"https://blog.yrpang.com/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"Nginx学习笔记（二）","date":"2020-01-31T02:07:31.000Z","path":"posts/39867/","text":"http模块的配置指令 前期准备阶段（框架代码处理）listen语句文档 https://nginx.org/en/docs/http/ngx_http_core_module.html#listen 用sock和本地端口的区别 通过sock不需要走Linux完整网络模型速度更快 server_name语句语法 指定多个域名，第一个为主域名 Syntax: server_name_in_redirect on | off;Default: server_name_in_redirect off;Context: http, server, location 主域名的作用是当server_name_in_redirect设置为on 的时候重定向会将domain改为主域名 e.g. server&#123; server_name primary.test.com second.test.com; server_name_in_redirect on; return 302 /redirect; &#125; 这样在返回的时候会重定向到http://primary.test.com/redirect 泛域名 *.test.com test.com/* 只支持在最前或最后 正则表达式 加前缀~^test/.com\\/\\d{2}$ 正则表达式可以使用()创建变量 e.g. server&#123; server_name ~^(www\\.)?(.+); location / &#123; root /site/$2; &#125; &#125; 其它 .test.com 可以用来匹配test.com 和*.test.com _匹配所有 &quot;&quot; 匹配没有传递Host 头部的 匹配顺序 精确匹配 *在前的泛域名 *在后的泛域名 正则表达式匹配(多次匹配的按照顺序进行选择) 匹配失败 —&gt; default server 不指定则为第一个 listen语句可以用default指定 Http请求的11个阶段 阶段 模块 POST_READ realip SERVER_REWRITE rewrite FIND_CONFIG REWRITE rewrite POST_REWRITE PREACCESS limt_conn, limt_req ACCESS auth_basic, access, auth_request POST_ACCESS PRECONTENT try_files CONTENT Index, autoindex, concat LOG access_log rewrite模块return指令return code [text] return code URL return URL 状态码 标准 意义 301 http1.0 永久重定向 302 http1.0 临时重定向，禁止缓存 303 http1.1 临时重定向，禁止缓存，允许改变方法 307 http1.1 临时重定向，禁止缓存，不允许改变方法 308 http1.1 永久重定向，不允许改变方法 444 nginx自定义 立即关闭连接，不反回数据 error_page指令1. error_page 404 /404.html; 2. error_page 500 502 503 504 /50x.html; 3. error_page 404 =200 /empty.gif; 4. error_page 404 = /404.php; 5. location / &#123; error_page 404 = @fallback; &#125; location @fallback &#123; proxy_pass http://backend; &#125; 6. error_page 403 http://example.com/forbidden.html; 7. error_page 404 =301 http://example.com/notfound.html rewrite指令在两个阶段都可能出现，此时要注意执行顺序 rewrite指令 Syntax: rewrite regex replacement [flag]; 作用是将regex替换成replacement regex可以使用正则表达式和分组生成新变量 如果relacement以http://或https:// 或$schema 开头直接返回302 flag： | flag | 意义 || :———-: | :————————————————————: || last | 用replacement进行新的location匹配 || break | 停止当前脚本的执行,停止rewrite模块其他指令 || redirect | 返回302重定向 || permanent | 返回301重定向 | 1 会按顺序执行 2 返回3.txt的内容 返回3.txt的内容 返回”third” 3 emmm rewrite_log on error_log ... 开启可以记录下所有重定向记录 if指令 find_config 阶段 location 指令 Syntax: location [ = | ~ | ~* | ^~ ] uri &#123; ... &#125;location @name { … }Default: —Context: server, location Syntax: merge_slashes on | off;Default:merge_slashes on;Context: http, server URL常见有有如下几种 前缀字符串 常规 =：精确匹配 ^~：匹配上后则不再进行正则匹配 正则表达式 ~：大小写敏感 ~*：忽略大小写 用于内部跳转的命名：@name 合并连续的/号：merge_slashes on 匹配顺序： 首先进行前缀匹配，发现=或者^~匹配则直接使用，否则记住最长匹配，按文件顺序进行正则表达式匹配，匹配则直接采用否则继续匹配，若均不匹配则使用上面记录的最长匹配。 PREACCESS阶段limit_conn模块(限制并发连接数)默认编译 使用共享内存，生效于全部worker 限制有效性取决于key的设计：postread阶段的realip模块获得的真实ip 主要指令： 定义共享内存以及key limit_conn_zone key zone=name:size key可以取$remote_addr binary_remote_addr等 limit_conn zone number 日志相关指令： limit_con_log_level控制日志级别 limit_conn_status控制返回错误码 limit_request模块(限制每个客户端每秒请求数)默认编译 使用共享内存，生效于全部worker 算法：leaky bucket算法 主要指令： 定义共享内存limit_req_zone key zone=name:size rate=rate ; 限制并发连接数limit_req zone=name [burst=number] [nodelay]; burst默认为0 nodelay立即处理不做延时 日志相关: limit_req_log_level和limit_conn_status 另：同时打开时limit_request模块优先生效 ACCESS阶段access模块指令： allow和deny auth_basic模块用户认证模块 auth_basic和auth_basic_user_file auth_request使用第三方权限验证系统(默认未编译)auth_request和auth_request_set 对上面三个模块做限制的satisfy指令satisfy all | any; all:必须所有模块放行才可以 any:任何一个放行就可以 注意问题 如果有return则不生效，即使在前面也不生效 模块间顺序有影响 PRECONTENT阶段try_files指令依次试图访问各个文件[没有的话返回code]try_files file ... [=code]; 应用：反向代理时可以先尝试在本地找，没有的话去上游 mirror模块流量拷贝 处理请求时，生成子请求访问其他服务，对子请求的返回值不做请求 mirror和mirror_request_body CONTENT阶段static模块(root和alias模块)功能：将url映射为静态文件提供访问 root和alias之间的差别： root会将location映射进文件路径，alias只会将location后的url映射 root有默认配置html content只能用在location里,root有上下文可以继承上文 例子location /root&#123; root html; &#125; loaction /alias&#123; alias html &#125; 则访问/root会访问html/root，/alias则是/html 几个变量 变量 值 request_filename 待访问文件完整路径 document_root 由URL和root/alias规则生成的文件夹路径 realpath_root 将document_root替换为真实路径(解决软连接等) content-type 日志：log_not_found on|off 当访问目标是目录但是没有带/的处理会触发301重定向 server_name_in_redirect on|off 控制是否返回server_name port_in_redirect on|off 是否附加端口 absolute_redirect on|off 控制是否返回域名 打开但是server_name为off时返回host index和auto_index当以/结尾时，默认index尝试寻找index.html，auto_index则尝试返回目录 然而因为index领先auto_index，所以如果目录下存在index指定的文件时就不会返回目录 一些指令autoindex autoindex_exact_size autoindex_format autoindex_localtime concat模块功能：当页面需要访问多个小文件时，拼接返回提高性能，由阿里巴巴提供 使用:下载https://github.com/alibaba/nginx-http-concat编译时添加--add-module=../nginx-http-concat/ 未完待续…","tags":[{"name":"nginx","slug":"nginx","permalink":"https://blog.yrpang.com/tags/nginx/"}]},{"title":"Nginx学习笔记（一）","date":"2020-01-25T12:18:44.000Z","path":"posts/3009/","text":"最近看陶辉老师的「Nginx核心知识100讲」做一些笔记，记录一些实用的配置和操作。 本篇记录nginx基本架构的讲解。 Mark一个日志监控程序Mark一个可视化的日志监控程序GoAccess 使用信号管理父子进程Nginx的进程包含master进程和worker进程，它们都是通过信号进行管理的，平时通过nginx -s command来进行管理实际上是同样的原理。 它们可以接收的信号及对应操作如下 Master进程（管理worker进程） 信号 功能 命令行 CHLD 子进程终止的时候向Master进程发送（用于监控子进程） TERM,INT 终止 stop QUIT 优雅的退出 quit HUP 重载 reload USR1 重新开始记录日志 reopen USR2 关闭旧Nginx主进程并启动新的 WINCH 退出旧的主进程 Worker进程 信号 功能 命令行 TERM,INT 启动,终止 stop QUIT 优雅的退出 quit USR1 重新开始记录日志 reopen WINCH 退出旧的主进程 使用kill -signal PID即可完成操作 热升级流程 将旧版本的Nginx替换，编译安装的话新程序直接编译到Nginx安装目录中 kill -USR2 旧主进程的PID(旧的Nginx主进程将会把自己的进程文件改名为.oldbin) kill -WINCH 旧主进程的PID逐步关闭旧的worker kill -QUIT 旧主进程的PID关闭旧的master备注：如果回滚向老进程发送HUB，向新进程发送QUIT Nginx基本架构及模块分类 同步异步与阻塞非阻塞阻塞与非阻塞主要在讨论操作系统底层的实现效果 阻塞： 进程运行所需条件没准备好时 操作系统将进程sleep 直到有条件满足时唤醒 非阻塞：进程运行所需条件没准备好时 在时间片用完前不会被切换掉 进程处理后续的操作 同步与异步讨论的是业务逻辑的事情 同步：调用接口后需要等待接口处理完数据并相应进程才能继续执行 异步：调用接口后不需要等待数据处理完可以继续执行，后续数据准备好通过一定的方式获得，例如回调 例子： 以超市买东西付款为例。 同步阻塞：需要等收银员扫描完我的商品后才能付款 我才能干别的事情。再这之前我一直看着她。 同步非阻塞：你先扫描 我先去看看别的东西。过一会看一眼服务员扫了多少了 也就是轮询。 异步非阻塞： 我就在隔壁买个咖啡。扫完了你叫我一声。 异步阻塞 应该不存在吧。 Linux的几个I/O模型Nginx用到的几个容器进程间通信使用共享内存 数组 ngxarray_t链表 ngx_list_t队列 ngx_q_t哈希表 ngx红黑树基数树 未完待续…","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.yrpang.com/tags/Nginx/"}]},{"title":"Github Action尝鲜-创建Hexo Deploy Action","date":"2019-11-10T03:12:18.000Z","path":"posts/47780/","text":"这几天弄好自己用的生成发布hexo博客用的workflow，感觉效果还不错，索性做成一个action发布一下，另外遇到一些问题也记录一下。 遇到的一些问题第一次使用alpine Docker不是很熟悉这个高度精简的系统 1、一些常用软件包的名字可能会变得不太一样，使用前在https://pkgs.alpinelinux.org/packages上查找一下 然后在Dockerfile里面RUN apk add xxx即可 2、注意GitHub action的运行环境是用root用户运行的，所以注意像添加known_hosts之类的要添加到/root/.ssh/known_hosts下面 3、npm的使用上局部安装的话使用npx hexo command 体验地址GitHub Markethttps://github.com/marketplace/actions/hexo-github-action","tags":[{"name":"GitHub-Action","slug":"GitHub-Action","permalink":"https://blog.yrpang.com/tags/GitHub-Action/"}]},{"title":"使用shell脚本判断git状态","date":"2019-11-09T11:58:40.000Z","path":"posts/43978/","text":"​在终于无法忍受包含中文的链接带来的种种问题以后，我决定把固定连接的格式修改一下，为此使用了hexo-abbrlink这个插件来进行文章编号的生成。 ​这个插件会在hexo g的时候生成文章编号并将编号存储在文章abbrlink字段里面，这就意味着在hexo g的过程中需要修改文章源文件才能将文章编号持久化存储起来。 ​这个过程在本地运行自然是没什么问题，然而如果使用GitHub actions自动生成并发布的话，就意味着在执行hexo g之后需要将当前的修改push回源代码仓库才行，这个操作看上去没什么问题，我甚至也发现了一个现成的github-push-action用于将代码push回原仓库。 ​但是在实际操作中我发现在文件没有任何文件发生更改时执行git commit -m &quot;something&quot; -a的返回值是1，而这会导致GitHub-actions判定该step执行状态为fail进而终止执行。 ​于是我考虑使用简单的shell语句来判断文件是否有修改，进而执行相应操作，将判断文件状态的几种可能方案记录如下： ​1、git diff --quiet --exit-code --cached可以用于判断已经追踪的文件是否有更改 ​2、if [ -z &quot;$(git status --porcelain)&quot; ]可以检查文件是否有修改 ​3、exit $( git status --porcelain | wc -l )可以直接作为返回值判0 具体代码如下 remote_repo=&quot;https://$&#123;GITHUB_ACTOR&#125;:$&#123;&#123;secrets.GITHUB_TOKEN&#125;&#125;@github.com/$&#123;GITHUB_REPOSITORY&#125;.git&quot; if [ -z &quot;$(git status --porcelain)&quot; ] then echo &quot;nothing to update.&quot; else git commit -m &quot;triggle by commit $&#123;&#123; github.sha &#125;&#125;. created by $&#123;&#123; github.workflow &#125;&#125;.&quot; -a git push &quot;$&#123;remote_repo&#125;&quot; HEAD:master fi 参考资料: https://www.itranslater.com/qa/details/2126861753253364736","tags":[{"name":"GitHub-Actions","slug":"GitHub-Actions","permalink":"https://blog.yrpang.com/tags/GitHub-Actions/"}]},{"title":"更新固定链接格式","date":"2019-11-09T11:38:54.000Z","path":"posts/8279/","text":"订阅了我博客RSS的朋友（如果真的有的话）可能发现一下子多了很多更新，得和大家说声抱歉，这只是因为我刚刚更新了博客固定链接的格式给大家带来打扰实在抱歉。","tags":[]},{"title":"浅谈GPG","date":"2019-11-03T09:56:54.000Z","path":"posts/37452/","text":"​ 写这个是因为前几天在配置好GitHub actions后勉强可以在网页上直接写东西了，上面一篇内容就是在网页写的，然而在发布之后查看commit记录的时候我发现通过网页提交的commit旁边会有一个Verified字样，点开以后会显示This commit was created on GitHub.com and signed with a verified signature using GitHub’s key. 感觉看上去挺有意思，于是尝试一下配置自己的GPG密钥，给commit记录签名。感觉网上的东西说的不是很让人明白，索性在这里再记录一下自己的体会。 ​ 下面的内容在macOS Catalina上进行。 GPG简介 1991年，程序员Phil Zimmermann为了避开政府监视，开发了加密软件PGP。这个软件非常好用，迅速流传开来，成了许多程序员的必备工具。但是，它是商业软件，不能自由使用。所以，自由软件基金会决定，开发一个PGP的替代品，取名为GnuPG。这就是GPG的由来。 from 阮一峰的网络日志 GPG密钥生成及使用软件安装 ​ 首先是安装，在macOS上面可以直接使用homebrew来进行，如果你还没有开始使用这个优秀的包管理工具，强烈推荐你了解一下，并开始使用。 brew install gnupg2 #有些教程提到一定要用gnupg2经过我的测试目前gnupg也已经指向gnupg2了是一样的 ​ 另外建议安装gpg-suite这个管理工具，在配置git的时候会更加方便，不过这和本文无关。 密钥生成 ​ 输入gpg --full-generate-key 按照提示进行操作，注意如果你的语言设置为中文的话在输入保护密码的时候会出现乱码不过不影响操作，不理会即可。 密钥管理 ​ 在仔细查阅资料后我发现，在较早期的时候因为兼容性问题对于是否使用子密钥有一定争议，但是对于现在来说在日常使用时使用子密钥而不是主密钥进行加密签名等操作已经被认为是一种最佳实践，所以很有必要学习一下。 ​ 在默认情况下，只想上面操作时会生成一对主密钥（用于签名）和一对子密钥（用于加密），使用gpg --list-secret-keys --keyid-format LONG即可查看。 如果想要生成其他子密钥使用gpg --edit-key [key-id]即可进入编辑模式，下面简单罗列一些常用命令备查： 使用addkey即可添加新的子密钥 gpg -o path/to/somewhere --export-secret-keys [key-id]导出私钥备份gpg -o path/to/somewhere --export-secret-subkeys 71C861745213C7导出私子密钥备份 ~/.gnupg/openpgp-revocs.d/吊销证书默认存储位置 gpg --delete-secret-keys [key-id]删除私钥 gpg --import path/to/key导入私钥 将吊销证书导入即可吊销本地 最佳实践https://nova.moe/openpgp-best-practices-key-configuration/ 一些不错的资料因为网络资料很齐全剩下的内容就不再详述了，参加下面几篇文章就好。 GnuPG2使用指北 如何使用 GPG 管理密钥 GPG 的正确使用姿势 Q&amp;A 关于git commit签名gitHub文档 使用 GPG 签名你的 Git Commit 我的GPG Key最后附上我的GPG Key","tags":[{"name":"GPG","slug":"GPG","permalink":"https://blog.yrpang.com/tags/GPG/"},{"name":"gitHub","slug":"gitHub","permalink":"https://blog.yrpang.com/tags/gitHub/"}]},{"title":"Hexo-GitHub-Actions","date":"2019-10-30T01:31:26.000Z","path":"posts/55815/","text":"我的博客是使用Hexo搭建的，一直面临着博客撰写不方便的问题，刚好GitHub推出了Actions功能，半期考刚刚结束，闲来无事索性尝一下借助这个工具来完成博客的自动生成部署工作，满足我网页写博客的需求。 一些介绍&amp;准备： 目前GitHub Actions还没有正式发布所以需要注册一个Beta版本的体验资格，不过因为距离正式发布已经很近了，所以这步没有难度直接去官网注册即可。另外现在官方也提供了很多方便的工具帮助使用者更快速的实现自己想要的功能。 另外附上官方文档参考 https://help.github.com/en/github/automating-your-workflow-with-github-actions workflow： 创建.github/workflow目录然后在目录里放workflow文件就好了 文件见 https://gist.github.com/yrpang/82a4a546c737d44cd58ca56595e3c335","tags":[{"name":"GitHub-Action","slug":"GitHub-Action","permalink":"https://blog.yrpang.com/tags/GitHub-Action/"}]},{"title":"Django动态表单","date":"2019-07-28T14:03:37.000Z","path":"posts/4202/","text":"def tests(request): field_dict=&#123;&#125; question = models.Questions.objects.all().order_by(&#x27;id&#x27;) for q in question: field_dict[&#x27;question_%s&#x27; %q.id] = fields.CharField( required=False, label = q.title, widget = widgets.Textarea ) MyAnswerForm = type(&#x27;MyAnswerForm&#x27;, (Form,), field_dict) if request.method == &#x27;GET&#x27;: ini = &#123;&#125; for q in question: ini[&#x27;question_%s&#x27;%q.id] = q.ans.first().answer formset = MyAnswerForm(initial=ini) return render(request, &#x27;tests.html&#x27;, &#123;&#x27;formset&#x27;:formset&#125;) else: ans = MyAnswerForm(request.POST) user = models.User.objects.get(id=request.session.get(&#x27;user_id&#x27;)) if ans.is_valid(): ans = ans.cleaned_data for key,v in ans.items(): k,qid = key.rsplit(&#x27;_&#x27;,1) try: a=models.Answers.objects.get(question__id=qid, user=user) a.answer=v a.save() except models.Answers.DoesNotExist: q = models.objcets.get(id=qid) models.objects.create(user=user, question=q, answer=v) formset = MyAnswerForm(request.POST) return render(request, &#x27;tests.html&#x27;, &#123;&#x27;formset&#x27;:formset&#125;) &lt;form action=&quot;/tests/&quot; id=&quot;answer&quot; method=&quot;post&quot;&gt; &#123;&#123; formset.management_form &#125;&#125; &#123;% csrf_token %&#125; &#123;&#123;formset&#125;&#125; &lt;button type=&quot;submit&quot;&gt;保存&lt;/button&gt; &lt;/form&gt; 参考资料https://www.cnblogs.com/ugfly/p/8215384.html","tags":[{"name":"后端","slug":"后端","permalink":"https://blog.yrpang.com/tags/%E5%90%8E%E7%AB%AF/"},{"name":"Django","slug":"Django","permalink":"https://blog.yrpang.com/tags/Django/"},{"name":"Python","slug":"Python","permalink":"https://blog.yrpang.com/tags/Python/"}]},{"title":"Django获取小程序码并返回","date":"2019-07-06T12:42:54.000Z","path":"posts/58401/","text":"今天实现小程序码获取和返回的一些功能遇到了一些问题，记录一下。 一、二维码的获取二维码的获取调用微信提供的wxacode.getUnlimited接口即可，这里注意微信的返回值有两种。如果获取成功则返回图片的二进制数据流，如果获取失败会返回json格式的错误代码。 另外注意请求参数需要使用json.dumps()封装为json格式，另外请求头要添加Application/json，并且附带的参数名称全为小写，否则的话会返回invalid format错误。 二、二维码处理并返回因为微信接口返回的为Buffer所以这里有两种思路： 1、将文件流base64编码返回给小程序，小程序直接解吗显示，代码如下 onLoad: function()&#123; var that = this; this.setData(&#123; src: &#x27;data:image/png;base64,&#x27; + DATA_FROM_BACKEND &#125;) &#125; &lt;image src=&#x27;&#123;&#123;src&#125;&#125;&#x27; class=&#x27;image&#x27;&gt;&lt;/image&gt; import base64 import requests def getQR(request): url = &quot;https://api.weixin.qq.com/wxa/getwxacodeunlimit?access_token=&quot;+str(access_token) headers = &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125; # 注意添加这个请求头 data = &#123;&#x27;scene&#x27;:&#x27;team_id=&#x27;+str(team_id), &#x27;is_hyaline&#x27;: True&#125; r = requests.post(url, data=json.dumps(data), headers=headers) return HttpResponse(base64.b64encode(r.content)) 2、将二进制存储为图片并返回url，代码如下： onLoad: function (options) &#123; var that = this that.setData(&#123; &quot;src&quot;: app.globalData.server_url+res.data.src &#125;) &#125; &lt;image src=&#x27;&#123;&#123;src&#125;&#125;&#x27; class=&#x27;image&#x27;&gt;&lt;/image&gt; def getQR(request): url = &quot;https://api.weixin.qq.com/wxa/getwxacodeunlimit?access_token=&quot;+str(access_token) headers = &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125; data = &#123;&#x27;scene&#x27;:&#x27;team_id=&#x27;+str(team_id), &#x27;is_hyaline&#x27;: True&#125; r = requests.post(url, data=json.dumps(data), headers=headers) i = BytesIO(r.content) roiImg = Image.open(i) print(type(roiImg)) savepath = os.path.join(os.getcwd() ,&#x27;media/&#x27;) name = str(int(time.time())) + r&#x27;.png&#x27; roiImg.save(str(savepath)+name, format=&#x27;PNG&#x27;) return JsonResponse(&#123;&#x27;code&#x27;: &#x27;0&#x27;, &#x27;src&#x27;: &#x27;/media/%s&#x27;%(name)&#125;) 之后设置一下nginx就ok 参考资料： 1 https://www.jianshu.com/p/28e6e090966a 2 https://blog.csdn.net/uikoo9/article/details/86088028 3 https://blog.csdn.net/qq_32446743/article/details/87780821 4 https://developers.weixin.qq.com/miniprogram/dev/api-backend/open-api/qr-code/wxacode.getUnlimited.html","tags":[{"name":"Python","slug":"Python","permalink":"https://blog.yrpang.com/tags/Python/"},{"name":"小程序","slug":"小程序","permalink":"https://blog.yrpang.com/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"}]},{"title":"ctf-web&misc学习小结","date":"2019-06-30T13:15:08.000Z","path":"posts/27393/","text":"参加“信息安全实验班”选拔前整理的一些东西。 一、vim查看二进制vim -b &quot;file_name&quot; %!xxd %!xxd -r 二、文件包含eval(&quot;var_dump($a);&quot;);函数可以将变量内容当作代码执行 get_file_contents(&#39;./path&#39;)可以获取文件内容 &lt;script language=php&gt;system(&quot;ls&quot;)&lt;/script&gt; 进阶如果进行了正则匹配的话可以使用GLOBALS显示所有变量 三、unicode编码解码使用document.write()可以直接显示 四、弱类型is_numeric()用来判断内容是不是数字 if($num==1)会进行类型转换所以1a == 1 五、域名解析修改请求头的host字段 六、JSFUCK是一种深奥的JavaScript 编程风格，直接运行 七、注意抓包观察返回的头八、本地访问x-forwarded-for:127.0.0.1字段表示访问的真实ip 九、你从哪里来Referer可以指示 注意： Referer: https://www.google.com没有结尾 十、unescape可以用来解码十一、php一些内容显示文件内容php://filter/read=convert.base64-encode/resource=./index.php php://input是POST data的输入流可以放进get_file_contents()函数读取 NULL的序列化是s:0:&quot;&quot;; ;的转义是%3B 十二、cookie模拟元素点击$(&quot;#cookie&quot;).mouseup() 十三、各种绕过MD5弱类型 s878926199a和s155964671a md5绕过方法：1.可以通过一些特殊的字符串，2.数组绕过。如果v1 v2是两个数组，md5函数不能获取到值，可以绕过。 strcmp绕过：将v3构造成数组。strcmp(array,string)=null=0 strcmp() 函数比较两个字符串，且对大小写敏感。 0 - 如果两个字符串相等 &lt;0 - 如果 string1 小于 string20 - 如果 string1 大于 string2 数组可以绕过sha1() 解题方法： GET请求： ?flag=&amp;gift= 十四、遇到自动跳转的curl url 十五、注意robots.txt可能会有收获十六、求getshell修改Content-Type字段 multipart/form-data任意一个字母为大写 拓展名 尝试 php2, php3, php4, php5，phps, pht, phtm, phtml 十七、Wifi密码破解crunch 11 11 -t 1391040%%%% &gt;&gt; lib.txt生成字典 十八、zip伪加密50 4B 03 04：这是头文件标记（0x04034b50）14 00：解压文件所需 pkware 版本00 00：全局方式位标记（有无加密） 50 4B 01 02：目录中文件文件头标记(0x02014b50)3F 00：压缩使用的 pkware 版本14 00：解压文件所需 pkware 版本00 00：全局方式位标记（有无加密，这个更改这里进行伪加密，改为09 00打开就会提示有密码了） 十九、隐写工具binwalk fcrackzip formost file fcrackzip -b -l 3-3 -c1 -v flag.zip Zip 50后面是开始 png的第二行是高和宽 栅栏密码 https://www.qqxiuzi.cn/bianma/zhalanmima.php 16进制 https://www.bejson.com/convert/ox2str/ 编码解吗大全 https://blog.csdn.net/pdsu161530247/article/details/75667218 附、杂记成绩出来了，成绩+机试排名22，这些天在反复纠结是否应该抓住这个机会，突然想明白了一个道理，觉得还是应该顺遂本心，向着自己的兴趣“自然语言处理”的方向努力，不该为了可能有所增加的保研机会就放弃自己的优势和积淀。相信不管在哪里不去努力都是不行的，希望自己能够顺遂本心，在自己选择的方向上努力前行。写在这里，记录一下，希望自己的选择是正确的。2019.7.6 面试前夜 参考资料： https://giraff3.cn/2018/08/13/Bugku%E9%A2%98%E8%A7%A3(WEB)/ http://www.she1don.cn/index.php/archives/23.html","tags":[{"name":"CTF","slug":"CTF","permalink":"https://blog.yrpang.com/tags/CTF/"}]},{"title":"[周报]2019年第20周","date":"2019-05-14T10:34:30.000Z","path":"posts/9864/","text":"从本周开始坚持每周写周报汇总学习生活和coding的情况，并展望未来。 总结&amp;开篇：期中考试很差，总结过去的半个学期自己过得太浪了，什么都是蜻蜓点水，哪项也没有静下心来深入，接下来好好调整一下。 制定接下来定一周的小目标： 完成手上的微信小程序项目 完成线性代数的复习回顾 完成波动光学部分的回顾整理 高数部分跟上进度 MOOC 体育打卡 坚持写周报","tags":[{"name":"周报","slug":"周报","permalink":"https://blog.yrpang.com/tags/%E5%91%A8%E6%8A%A5/"}]},{"title":"Tensoflow-logistic-regression","date":"2019-05-02T15:43:46.000Z","path":"posts/20414/","text":"之前数模参赛时遇到的一个问题，当时因为比赛的原因不方便马上发，现在发出来。 在本次数学建模中涉及到了logistic-regression模型的应用，简单记录一下Tensorflow的实现。 1、环境我比较偷懒，直接使用了Google Cloud Platform免去了配置Tensorflow环境的麻烦。 2、代码import pandas as pd # 用于读取数据文件 import tensorflow as tf import matplotlib.pyplot as plt # 用于画图 import numpy as np df &#x3D; pd.read_csv(&quot;input.csv&quot;, header&#x3D;None) train_data &#x3D; df.values print(train_data) train_X &#x3D; train_data[:, :-1] train_y &#x3D; train_data[:, -1:] feature_num &#x3D; len(train_X[0]) sample_num &#x3D; len(train_X) print(&quot;Size of train_X: &#123;&#125;x&#123;&#125;&quot;.format(sample_num, feature_num)) print(&quot;Size of train_y: &#123;&#125;x&#123;&#125;&quot;.format(len(train_y), len(train_y[0]))) X &#x3D; tf.placeholder(tf.float32) y &#x3D; tf.placeholder(tf.float32) W &#x3D; tf.Variable(tf.zeros([feature_num, 1])) b &#x3D; tf.Variable([-.9]) db &#x3D; tf.matmul(X, tf.reshape(W, [-1, 1])) + b hyp &#x3D; tf.sigmoid(db) cost0 &#x3D; y * tf.log(hyp) cost1 &#x3D; (1 - y) * tf.log(1 - hyp) cost &#x3D; (cost0 + cost1) &#x2F; -sample_num loss &#x3D; tf.reduce_sum(cost) optimizer &#x3D; tf.train.GradientDescentOptimizer(0.001) train &#x3D; optimizer.minimize(loss) init &#x3D; tf.global_variables_initializer() sess &#x3D; tf.Session() sess.run(init) feed_dict &#x3D; &#123;X: train_X, y: train_y&#125; for step in range(1000000): sess.run(train, &#123;X: train_X, y: train_y&#125;) if step % 10000 &#x3D;&#x3D; 0: print(step, sess.run(W).flatten(), sess.run(b).flatten()) # 绘图 w &#x3D; [0.7672361 , -0.276697 , -0.19542742] b &#x3D; 0.09650069 from mpl_toolkits.mplot3d import Axes3D x1 &#x3D; train_data[:, 0] x2 &#x3D; train_data[:, 1] x3 &#x3D; train_data[:, 2] y &#x3D; train_data[:, -1:] fig&#x3D;plt.figure() ax&#x3D;Axes3D(fig) for x1p, x2p, x3p, yp in zip(x1, x2, x3, y): if yp &#x3D;&#x3D; 0: ax.scatter(x1p, x2p, x3p, c&#x3D;&#39;r&#39;) else: ax.scatter(x1p, x2p, x3p, c&#x3D;&#39;g&#39;) ax.set_zlabel(&#39;Z&#39;) # 坐标轴 ax.set_ylabel(&#39;Y&#39;) ax.set_xlabel(&#39;X&#39;) a &#x3D; 0.7672361 b &#x3D; -0.276697 c &#x3D; -0.19542742 d &#x3D; 0.09650069 x1 &#x3D; np.linspace(-1,1,10) y1 &#x3D; np.linspace(-1,1,10) X,Y &#x3D; np.meshgrid(x1,y1) Z &#x3D; (d - a*X - b*Y) &#x2F; c fig &#x3D; plt.figure() ax &#x3D; fig.gca(projection&#x3D;&#39;3d&#39;) surf &#x3D; ax.plot_surface(X, Y, Z) 结果# Result # 0 [ 0.7707945 -0.27244025 -0.19312732] [0.08507074] # 10000 [ 0.77019846 -0.2730363 -0.19343074] [0.08675246] # 20000 [ 0.76964736 -0.27363235 -0.19366762] [0.08829048] # 30000 [ 0.7692501 -0.27412957 -0.19393419] [0.08960892] # 40000 [ 0.7689034 -0.27445695 -0.19417214] [0.09070877] # 50000 [ 0.7686214 -0.27475497 -0.19436422] [0.09161869] # 60000 [ 0.7683936 -0.275053 -0.19451982] [0.09238537] # 70000 [ 0.7682283 -0.27535102 -0.19466883] [0.09303201] # 80000 [ 0.76810503 -0.27564904 -0.19481784] [0.09360377] # 90000 [ 0.76798075 -0.27594706 -0.19491854] [0.09411547] # 100000 [ 0.7678499 -0.2761182 -0.19500598] [0.09455331] # 110000 [ 0.76773375 -0.27622774 -0.19508578] [0.09492187] # 120000 [ 0.7676398 -0.27631634 -0.19515029] [0.0952199] # 130000 [ 0.7675626 -0.27638906 -0.19520319] [0.09546462] # 140000 [ 0.7674922 -0.27645552 -0.19525155] [0.09568814] # 150000 [ 0.76744366 -0.2765014 -0.19528496] [0.09584232] # 160000 [ 0.7673967 -0.27654564 -0.19531724] [0.09599134] # 170000 [ 0.76735574 -0.27658433 -0.19534537] [0.09612132] # 180000 [ 0.76733226 -0.2766065 -0.19536147] [0.09619582] # 190000 [ 0.7673087 -0.27662855 -0.1953776 ] [0.09627033] # 200000 [ 0.7672852 -0.27665073 -0.1953937 ] [0.09634484] # 210000 [ 0.7672618 -0.2766729 -0.19540988] [0.09641934] # 220000 [ 0.7672383 -0.2766951 -0.19542597] [0.09649385] # 230000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 240000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 250000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 260000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 270000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 280000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 290000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 300000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 310000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 320000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 330000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 340000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 350000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 360000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] # 370000 [ 0.7672361 -0.276697 -0.19542742] [0.09650069] 参考资料：https://segmentfault.com/a/1190000009954640http://bbs.bugcode.cn/t/20913","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://blog.yrpang.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"},{"name":"数学建模","slug":"数学建模","permalink":"https://blog.yrpang.com/tags/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"}]},{"title":"访问网页的过程究竟发什么了什么","date":"2019-04-11T08:43:40.000Z","path":"posts/43826/","text":"DNS查询得到IP首先检查浏览器缓存 —&gt; 检查本机缓存 —&gt; 使用host —&gt; 路由器缓存 —&gt; DNS服务器递归查询 刷新Chrome缓存chrome://net-internals/#dns 修改host会导致本机缓存被刷新，而浏览器缓存不刷新。 清理本地缓存: sudo dscacheutil -flushcache TCP/IP请求http的本质就是 tcp/ip请求 连接过程：三次握手四次挥手三次握手：客户端：hello，你是server么？ 服务端：hello，我是server，你是client么 客户端：yes，我是client 四次挥手：主动方：我已经关闭了向你那边的主动通道了，只能被动接收了 被动方：收到通道关闭的信息 被动方：那我也告诉你，我这边向你的主动通道也关闭了 主动方：最后收到数据，之后双方无法通信 五层因特网协议栈从应用层的发送http请求，到传输层通过三次握手建立tcp/ip连接，再到网络层的ip寻址，再到数据链路层的封装成帧，最后到物理层的利用物理介质传输。服务端的接收就是反过来的步骤。 五层因特尔协议栈其实就是：1.应用层(dns,http) DNS解析成IP并发送http请求2.传输层(tcp,udp) 建立tcp连接（三次握手）3.网络层(IP,ARP) IP寻址4.数据链路层(PPP) 封装成帧5.物理层(利用物理介质传输比特流) 物理传输（然后传输的时候通过双绞线，电磁波等各种介质） 其实也有一个完整的OSI七层框架:表示层：主要处理两个通信系统中交换信息的表示方式，包括数据格式交换，数据加密与解密，数据压缩与终端类型转换等会话层：它具体管理不同用户和进程之间的对话，如控制登陆和注销过程 服务器接收到请求到对应后台接收到请求请求过程1、浏览器组装好Request发送给WEB服务器2、Nginx接受到Request之后根据请求资源类型进行分类,如果请求静态资源,Nginx会检索静态资源,并直接返回,如果是请求动态资源,会交给应用服务器.当然这其中会有请求缓冲,负载均衡等步骤.3、实现了wsgi网管接口的应用服务器接收到http请求后,利用Werkzeng等网络编程工具实现的python程序(flask框架等)会根据request内容生成Response并返回给Nginx4、Nginx缓冲Response,并将其返回给浏览器 web服务器Nginx Apache 之类的叫做服务器软件，顾名思义，这是一个软件，用于运行web 服务的软件。也常被称作web服务器， HTTP服务器，其作用是用来处理HTTP协议的，且只能处理静态内容。也就是把服务器文件系统中的每一个资源对照成URI，然后通过HTTP协议把这些已经存在的资源传给发起HTTP请求的客户端。他将动态资源交给应用服务器处理，静态资源则由web服务器直接返回浏览器，这样就减轻了应用服务器压力。 应用服务器仅仅响应静态内容是不够的，人们还需要动态的处理内容，返回动态的信息给客户端。 这就用到了服务器脚本。人们为了统一服务器脚本和web服务器之间的信息交互方式，提出了CGI，统一化标准。WSGI规定了web服务器与web应用程序之间的标准接口，以确保web应用程序在不同的web服务器之间具有可移植性，在python web开发中，主流的选择是Gunicorn，uWSGI等实现WSGI的容器。 两者的区别web服务器负责处理HTTP协议，应用服务器既可以处理HTTP协议，也能处理其他协议。web服务器处理静态页面内容，动态内容通过WSGI接口交给应用服务器来处理。 负载均衡用户发起的请求都指向调度服务器（反向代理服务器，譬如安装了nginx控制负载均衡），然后调度服务器根据实际的调度算法，分配不同的请求给对应集群中的服务器执行，然后调度器等待实际服务器的HTTP响应，并将它反馈给用户。 一些协议中间件对比WSGI:Python Web Server Gateway Interface python 定义的web服务器与web应用程序之间的简单而通用的接口Werkzeng: Werkzeug是Python基于WSGI协议写的函数库，它的应用很广泛flask: 基于Werkzeng实现的轻量级web框架Gunicorn: wsgi容器,可以用Gunicorn跑用flask等Werkzeng框架实现的程序,这样就实现了一个应用服务器 解析页面流程解析HTML，构建DOM树 解析CSS，生成CSS规则树 合并DOM树和CSS规则，生成render树 布局render树（Layout/reflow），负责各元素尺寸、位置的计算 绘制render树（paint），绘制页面像素信息 浏览器会将各层的信息发送给GPU，GPU会将各层合成（composite），显示在屏幕上 参考资料:https://www.jianshu.com/p/b5f58e5bed15https://mp.weixin.qq.com/s?__biz=MzAxODE2MjM1MA==&amp;mid=2651553818&amp;idx=1&amp;sn=3ce840113d28ee2b2cafe4c7fc48ef91&amp;chksm=802557dbb752decd2118e3ad7a3ea803a0c41c6594f539fc54830dae9bbc2242b2fc03e7fb1c&amp;scene=21#wechat_redirect","tags":[{"name":"uwsgi","slug":"uwsgi","permalink":"https://blog.yrpang.com/tags/uwsgi/"},{"name":"http","slug":"http","permalink":"https://blog.yrpang.com/tags/http/"}]},{"title":"腾讯云 gaierror: Temporary failure in name resolution错误解决","date":"2019-04-09T05:47:19.000Z","path":"posts/25327/","text":"今天中午看图猜话小程序的demo刚上线，告警群里就开始没完没了的报告脚本错误（此处略去心中一万句mmp… 问题：看了一下uwsgi.log发现如下错误没有规律的间歇性出现 Internal Server Error: / Traceback (most recent call last): File &quot;/usr/local/lib/python3.7/site-packages/urllib3/connection.py&quot;, line 159, in _new_conn (self._dns_host, self.port), self.timeout, **extra_kw) File &quot;/usr/local/lib/python3.7/site-packages/urllib3/util/connection.py&quot;, line 57, in create_connection for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM): File &quot;/usr/local/lib/python3.7/socket.py&quot;, line 748, in getaddrinfo for res in _socket.getaddrinfo(host, port, family, type, proto, flags): socket.gaierror: [Errno -3] Temporary failure in name resolution During handling of the above exception, another exception occurred: Traceback (most recent call last): File &quot;/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py&quot;, line 600, in urlopen chunked=chunked) File &quot;/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py&quot;, line 343, in _make_request self._validate_conn(conn) File &quot;/usr/local/lib/python3.7/site-packages/urllib3/connectionpool.py&quot;, line 839, in _validate_conn conn.connect() File &quot;/usr/local/lib/python3.7/site-packages/urllib3/connection.py&quot;, line 301, in connect conn = self._new_conn() File &quot;/usr/local/lib/python3.7/site-packages/urllib3/connection.py&quot;, line 168, in _new_conn self, &quot;Failed to establish a new connection: %s&quot; % e) urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.VerifiedHTTPSConnection object at 0x7f201d4460b8&gt;: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution ................ 解决：Temporary failure in name resolution这句话看上去是在说DNS解析有问题，百度了一下发现有人在使用腾讯云时遇到类似错误，参照他的解决方案，问题解决，具体操作如下： sudo vi /etc/resolv.conf， 发现里面只有一条 nameserver 127.0.0.53然而 /etc/resolvconf/resolv.conf.d/base 里面有俩条记录，手动把这俩条记录加到 /etc/resolv.conf 就正常了。 目前问题暂时解决。 参考资料:https://low.bi/p/azd1wpBgZJlhttps://www.cnblogs.com/ruigu/p/8603247.html","tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.yrpang.com/tags/Linux/"},{"name":"uwsgi","slug":"uwsgi","permalink":"https://blog.yrpang.com/tags/uwsgi/"},{"name":"腾讯云","slug":"腾讯云","permalink":"https://blog.yrpang.com/tags/%E8%85%BE%E8%AE%AF%E4%BA%91/"}]},{"title":"Miniflux搭建-Nginx反代-LetsEncrypt证书配置","date":"2019-03-04T14:04:10.000Z","path":"posts/22683/","text":"Miniflux搭建:这部分没啥说的，官方文档很清晰，照着做就完了。 配置Nginx反代：server&#123; listen [::]:443 ssl ipv6only&#x3D;on; # managed by Certbot listen 443 ssl; # managed by Certbot ssl_certificate &#x2F;etc&#x2F;letsencrypt&#x2F;live&#x2F;rss.lnception.cn&#x2F;fullchain.pem; # managed by Certbot ssl_certificate_key &#x2F;etc&#x2F;letsencrypt&#x2F;live&#x2F;rss.lnception.cn&#x2F;privkey.pem; # managed by Certbot include &#x2F;etc&#x2F;letsencrypt&#x2F;options-ssl-nginx.conf; # managed by Certbot ssl_dhparam &#x2F;etc&#x2F;letsencrypt&#x2F;ssl-dhparams.pem; # managed by Certbot server_name rss.lnception.cn; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;127.0.0.1:8080&#x2F;; proxy_set_header Host $host; proxy_redirect off; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; &#125; &#125; server &#123; if ($host &#x3D; rss.lnception.cn) &#123; return 301 https:&#x2F;&#x2F;$host$request_uri; &#125; # managed by Certbot listen 80 ; listen [::]:80 ; server_name rss.yrpang.com; return 404; # managed by Certbot &#125; LetsEncrypt证书配置https://certbot.eff.org/lets-encrypt/ubuntubionic-nginx 参考资料：https://docs.miniflux.app/en/2.0.7/configuration.html","tags":[]},{"title":"postgresql安装与使用","date":"2019-03-03T14:30:22.000Z","path":"posts/48821/","text":"今天在使用Miniflux时需要用到postgresql数据库，折腾了好长时间才搞明白这个东西怎么用。开篇之前我要先吐槽postgresql好难用啊，太他妈难用了啊啊啊。3.10 更正：刚看到python社区发的报告，这数据库使用率第一？？这样看来大概是我坑爹emmm……不敢吐槽了，赶紧好好看看咋用。 环境Ubuntu 18.4LTSpostgresql 最新版 问题：1、安装：首先安装使用sudo apt install postgresql安装之后会出现Success. You can now start the database server using: /usr/lib/postgresql/10/bin/pg_ctl -D /var/lib/postgresql/10/main -l logfile start Ver Cluster Port Status Owner Data directory Log file 10 main 5432 down postgres /var/lib/postgresql/10/main /var/log/postgresql/postgresql-10-main.log此处注意postgresql只能使用非特权用户运行，管理之类的也只能使用postgres用户操作，所以接下来su - postgres 切换以后上面提示里面的命令运行后会报错说配置文件不存在 接下来可以手动指定/etc/postgresql目录下面的配置文件，也可以重新初始化数据库使用/usr/lib/postgresql/10/bin/pg_ctl initdb -D /var/lib/postgresql/11重新初始化一个数据库这样子配置文件就在这个文件夹 可以直接使用/usr/lib/postgresql/10/bin/pg_ctl -D /var/lib/postgresql/11 -l logfile start启动 到此安装完毕。 2、卸载：我们正常思路可能是用sudo apt remove postgresql然而事实上并不行 重新安装后会发现配置文件还在没法重新初始化 这里搬运一下完全卸载方法:1.apt-get --purge remove postgresql\\* //删除软件本体 2.rm -r /etc/postgresql/ //删除配置文件 3.rm -r /etc/postgresql-common/ //同上 4.rm -r /var/lib/postgresql/ //同上 5.userdel -r postgres //删除软件自动创建的用户 6.groupdel postgres //删除其用户组 参考资料：http://www.u3coding.com/2017/08/27/%E5%BC%80%E6%BA%90%E6%95%B0%E6%8D%AE%E5%BA%93postgresql%E5%AE%89%E8%A3%85%E5%8D%B8%E8%BD%BD%E6%80%BB%E7%BB%93/https://github.com/yandex-qatools/postgresql-embedded/issues/74https://blog.csdn.net/dyx1024/article/details/6594851https://juejin.im/post/5b2cb169e51d4558cc35bd7c","tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.yrpang.com/tags/Linux/"}]},{"title":"用户ID生成算法总结","date":"2019-02-04T12:01:03.000Z","path":"posts/7566/","text":"参考资料 https://tech.meituan.com/2017/04/21/mt-leaf.html https://juejin.im/post/5b3a23746fb9a024e15cad79 https://www.jianshu.com/p/9d7ebe37215e","tags":[{"name":"后端","slug":"后端","permalink":"https://blog.yrpang.com/tags/%E5%90%8E%E7%AB%AF/"}]},{"title":".gitignore生效问题","date":"2019-01-31T07:31:00.000Z","path":"posts/54247/","text":"修改.gitignore会出现不生效的情况，清除缓存即可 git rm -r --cached . #清除缓存 git add . #重新trace file git commit -m &quot;update .gitignore&quot; #提交和注释 git push origin master #可选，如果需要同步到remote上的话","tags":[{"name":"git","slug":"git","permalink":"https://blog.yrpang.com/tags/git/"}]},{"title":"微信小程序-改变列表内元素属性","date":"2019-01-30T16:59:26.000Z","path":"posts/39954/","text":"问题：微信小程序渲染一个列表，列表中有包含按钮。 按钮状态有由列表特定item的一个属性决定。 需求是 点击按钮，触发操作，同时改变其状态。 尝试了n次才找到办法，记录一下。 Page(&#123; data: &#123; match_id: 0, teams: [], &#125;, follow: function(e)&#123; var that=this var team_id = e.currentTarget.dataset.team_id var num = e.target.id wx.request(&#123; url: app.globalData.server_url + &#x27;team/follow/&#x27;, method: &quot;POST&quot;, data:&#123; openid: app.globalData.openid, teamid: team_id &#125;, success(res)&#123; that.setData(&#123; [&#x27;teams[&#x27; + num + &#x27;].mark&#x27;] : !that.data.teams[num].mark //关键在这里的实现 &#125;) &#125; &#125;) &#125;, &#125;) 如上面代码所示： 在this.setData(&#123;&#125;)中可以使用[str]的形式指定要改变元素的地址 另外&quot;变量名&quot;:data则可以使用变量作为被改变元素地址 参考资料: https://blog.csdn.net/fxjzzyo/article/details/79263198","tags":[{"name":"小程序","slug":"小程序","permalink":"https://blog.yrpang.com/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"前端","slug":"前端","permalink":"https://blog.yrpang.com/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"微信小程序-flex布局","date":"2019-01-30T16:55:57.000Z","path":"posts/49201/","text":"微信小程序布局主要有两种： 一是相对定位、绝对定位，繁琐麻烦，含兼容性不好 二是flex布局，这里有几篇简洁清晰的教程，记录一下 https://developers.weixin.qq.com/ebook?action=get_post_info&amp;docid=00080e799303986b0086e605f5680a https://www.jianshu.com/p/e4f371d6dc5e https://www.jianshu.com/p/f1c30c8bd3b3 https://www.jianshu.com/p/f82262002f8a","tags":[{"name":"小程序","slug":"小程序","permalink":"https://blog.yrpang.com/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"前端","slug":"前端","permalink":"https://blog.yrpang.com/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"python-字符串-列表-相互转换","date":"2019-01-27T05:30:43.000Z","path":"posts/34603/","text":"字符串（str）-&gt; 列表（list）str1 = &quot;a,b,ccc&quot; list1 = str1.split(&quot;,&quot;) # 括号里是分隔符 print(list1) 输出： [a,b,ccc] 列表（list）-&gt;字符串（str）str2 = &quot;.&quot;.join(list1) # 引号里面为分隔符 print(str2) 输出： a.b.ccc 参考资料: https://blog.csdn.net/roytao2/article/details/53433373","tags":[{"name":"Python","slug":"Python","permalink":"https://blog.yrpang.com/tags/Python/"}]},{"title":"uwsgi-进程管理","date":"2019-01-27T05:23:12.000Z","path":"posts/44279/","text":"为了管理uwsgi进程的启动和运行，首先在配置文件中添加如下配置： stats=%(chdir)/uwsgi/uwsgi.status pidfile=%(chdir)/uwsgi/uwsgi.pid 使用：uwsgi --iniuwsgin.ini正常启动uwsgi进程 停止进程 uwsgi --stop uwsgi/uwsgi.pid 重启进程：uwsgi --reload uwsgi/uwsgi.pid 查看进程状态： uwsgi --connect-and-readuwsgi/uwsgi.status 参考资料: https://blog.csdn.net/weixin_39584758/article/details/80356000","tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.yrpang.com/tags/Linux/"},{"name":"uwsgi","slug":"uwsgi","permalink":"https://blog.yrpang.com/tags/uwsgi/"}]},{"title":"微信小程序发送模版消息","date":"2019-01-26T09:09:02.000Z","path":"posts/1444/","text":"今天主要遇到两个问题，一个是小程序登陆态暂存与暂存时间管理的问题，另一个是小程序模版消息后端接口调用返回47001 data format error错误的问题。 小程序登陆态暂存与暂存时间管理这部分直接贴腾讯官方文档 https://developers.weixin.qq.com/ebook?action=get_post_info&amp;docid=000a2c7c9f4a981b0086bd31e5b40a 小程序模版消息后端接口调用返回47001 data format error错误这部分问题是因为Django默认格式是application/x-www-form-urlencoded而小程序后台需要json格式才行 具体解决方法可能会因为请求发送方式的不同而改变，我这里是用的requests库 解决 首先在请求头里面设置请求格式为application/json，然后使用json封装请求数据，具体实现如下： import requests import json data = &#123; &#x27;a&#x27;: 123, &#x27;b&#x27;: 456 &#125; headers = &#123;&#x27;Content-Type&#x27;: &#x27;application/json&#x27;&#125; response = requests.post(url=&#x27;url&#x27;, headers=headers, data=json.dumps(data)) #json.dump()封装 参考资料: https://blog.csdn.net/weixin_41004350/article/details/78705415 https://developers.weixin.qq.com/miniprogram/dev/api/sendTemplateMessage.html","tags":[{"name":"Python","slug":"Python","permalink":"https://blog.yrpang.com/tags/Python/"},{"name":"小程序","slug":"小程序","permalink":"https://blog.yrpang.com/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"}]},{"title":"Python添加ssl模块","date":"2019-01-24T12:19:29.000Z","path":"posts/5070/","text":"又遇到一个坑，Django需要_ssl模块，默认安装的Python没有，重新编译一下，教程很多，我简单记录一下。 进入Python的源码目录 cd Python-3.7.2/Modules vim Setup.dist 去掉下面几行前面的注释：# Socket module helper for SSL support; you must comment out the other # socket line above, and possibly edit the SSL variable: #SSL=/usr/local/ssl#_ssl _ssl.c \\ # -DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \\ # -L$(SSL)/lib -lssl -lcrypto ./configure make sudo make install 这样就完成了。 参考资料： https://www.cnblogs.com/stragon/p/5884205.html","tags":[{"name":"Django","slug":"Django","permalink":"https://blog.yrpang.com/tags/Django/"},{"name":"Linux","slug":"Linux","permalink":"https://blog.yrpang.com/tags/Linux/"}]},{"title":"Linux-程序的编译安装","date":"2019-01-24T11:55:38.000Z","path":"posts/25075/","text":"一直使用Mac习惯了homebrew的简单快捷，几乎从来没从源码编译安装过软件，这次服务器用的Ubuntu，其中有些用到的软件版本系统包管理没有提供，只能从源码编译安装，所以整理一下Linux编译安装软件的一些知识。 编译安装一般步骤步骤没啥可说的，一般就是下载源码./configure make make install 这几个步骤，中间出现问题解决就可以。下面主要探讨的是软件的默认安装目录以及，非标准目录安装的一些问题。 非标准安装一般情况下 ./cofigure后面添加相应参数可以控制生成的Makefile文件，进而控制编译出来的版本，具体参数参照对应软件的文档即可。例如--prefix参数可以控制安装位置。 这几步在做什么./configure是建立Makefile 文件 make是编译 sudo make install安装 剩下的其他问题直接看这篇文章吧写的太好了，索性直接贴链接了 https://www.jianshu.com/p/39101098ebbe https://my.oschina.net/surjur/blog/349464","tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.yrpang.com/tags/Linux/"}]},{"title":"ubuntu升级-sshd无法启动","date":"2019-01-24T05:51:55.000Z","path":"posts/35455/","text":"问题描述ssh无法连接服务器，查看发现sshd没启动 尝试sudo systemctl start sshd启动报错: Job for ssh.service failed because the control process exited with error code. see systemctl status ssh.service and journalctl -xe for details. 解决：首先sudo /usr/sbin/sshd -T检查配置发现bad ssh2 cipher spec错误 使用ssh -Q cipher看下目前使用的ciphers 编辑/etc/ssh/sshd_config修改Ciphers****就OK 再次sudo /usr/sbin/sshd -T发现bad ssh2 cipher spec同理ssh -Q mac看下，然后改配置文件，再次sudo /usr/sbin/sshd -T发现正常了 sudo systemctl start sshd启动成功，问题解决。 最后，吐槽一下腾讯后台没法复制粘贴，都是手输的。 参考资料： https://kingzcheung.com/archives/116.html https://forums.freebsd.org/threads/sshd-wont-start.51784/","tags":[{"name":"Linux","slug":"Linux","permalink":"https://blog.yrpang.com/tags/Linux/"}]},{"title":"django-uwsgi-部署","date":"2019-01-22T12:28:23.000Z","path":"posts/37675/","text":"今天在把Django部署到服务器的时候，本地跑得好好的东西，遇到了各种奇葩问题的轮番轰炸。 把我逼到抓狂，网上各种说法都有，各种奇葩解决方案，乱七八糟。终于搞定，特此记录一下。 开发环境Ubuntu 16.01（没用最新是因为腾讯云最新就这个，一升级就炸，好吧是我自己太垃圾了） Python3.7（从源码编译安装） 遇到问题问题1: ubuntu默认有python2.7和python3.5，没python3.7apt install不星，最高3.5，习惯了homebrew一键搞定，还真挺懵逼，发现自己这个所谓的运维居然没从源码编译安装过东西，太傻逼了，一脸懵。 解决1：没啥说的，编译安装就完了。 $ wget https://www.python.org/downloads/release/python-370/ $ tar -zxvf Python-3.7.0.tgz # 把依赖库装一下子(并不知道为啥是这些，待思考) $ sudo apt-get install zlib1g-dev libbz2-dev libssl-dev libncurses5-dev libsqlite3-dev libreadline-dev tk-dev libgdbm-dev libdb-dev libpcap-dev xz-utils libexpat1-dev liblzma-dev libffi-dev libc6-dev $ cd /path/to/downloaded/file/ $ sudo ./configure $ sudo ./make $ sudo ./make install P.S. 如果还缺东西 那就缺啥补啥 少啥装啥 问题2: ubuntu安装mysql $ sudo apt-get install mysql-server mysql-client # 让输密码就数一下 这是root的密码 这步倒是没出啥问题，但是Django跑起来的时候会出现Error loading MySQLdb module: No module named ‘MySQLdb’ 因为Python3.5+并不支持MySQLdb，使用MySql可以使用pymysql代替，据说两者使用方式相同 解决2：$ pip install pymysql ... 在init.py中添加 import pymysql pymysql.install_as_MySQLdb() 问题3: 配置uwsgi$ pip3 install uwsgi ... nginx配置文件: # mysite_nginx.conf # the upstream component nginx needs to connect to upstream django &#123; # server unix:///path/to/your/mysite/mysite.sock; # for a file socket server 127.0.0.1:8001; # for a web port socket (we&#x27;ll use this first) &#125; # configuration of the server server &#123; # the port your site will be served on listen 8000; # the domain name it will serve for server_name .example.com; # substitute your machine&#x27;s IP address or FQDN charset utf-8; # max upload size client_max_body_size 75M; # adjust to taste # Django media location /media &#123; alias /path/to/your/mysite/media; # your Django project&#x27;s media files - amend as required &#125; location /static &#123; alias /path/to/your/mysite/static; # your Django project&#x27;s static files - amend as required &#125; # Finally, send all non-media requests to the Django server. location / &#123; uwsgi_pass django; include /path/to/your/mysite/uwsgi_params; # the uwsgi_params file you installed &#125; &#125; uwsg配置文件: # mysite_uwsgi.ini file [uwsgi] # Django-related settings # the base directory (full path) chdir = /path/to/your/project # Django&#x27;s wsgi file module = mysite.wsgi:application # process-related settings # master master = True pidfile=/tmp/project-master.pid # maximum number of worker processes processes = 10 # the socket (use the full path to be safe socket = /path/to/your/project/mysite.sock # ... with appropriate permissions - may be needed # chmod-socket = 664 max-requests=5000 # clear environment on exit vacuum = True daemonize=/var/log/uwsgi/yourproject.log 应用配置文件 $ uwsgi --ini mysite_uwsgi.ini # the --ini option is used to specify a file 问题4: Django admin页面css等静态文件丢失这个其实文档里面写清楚了，没注意看。 解决：修改seetings.py 添加 STATIC_ROOT = &quot;/var/www/example.com/static/&quot; 运行python manage.py collectstatic收集静态文件。 在linux配置文件中设置好地址，就OK。 参考资料： https://blog.csdn.net/hzlnice/article/details/81140865 https://www.jianshu.com/p/3111290b87f4 https://www.jianshu.com/p/968403165b92 https://uwsgi-docs-zh.readthedocs.io/zh_CN/latest/tutorials/Django_and_nginx.html https://docs.djangoproject.com/zh-hans/2.1/ref/databases/#mysql-notes https://docs.djangoproject.com/zh-hans/2.1/howto/deployment/wsgi/uwsgi/","tags":[{"name":"Django","slug":"Django","permalink":"https://blog.yrpang.com/tags/Django/"},{"name":"Nginx","slug":"Nginx","permalink":"https://blog.yrpang.com/tags/Nginx/"},{"name":"uwsgi","slug":"uwsgi","permalink":"https://blog.yrpang.com/tags/uwsgi/"}]},{"title":"Nginx+php-fpm","date":"2018-11-23T07:54:42.000Z","path":"posts/49243/","text":"一、正向代理与反向代理正向与反向是相对于人的感知来说的 可以感知 —-&gt; 正向 不可以感知 —-&gt; 反向 二、php-fpm是啥？php-fpm是 FastCGI 的实现，并提供了进程管理的功能。进程包含 master 进程和 worker 进程两种进程。master 进程只有一个，负责监听端口，接收来自 Web Server 的请求，而 worker 进程则一般有多个(具体数量根据实际需要配置)，每个进程内部都嵌入了一个 PHP 解释器，是 PHP 代码真正执行的地方。 三、ngnix的配置默认配置文件路径/etc/ngnix/ngnix.conf 简单配置一下 server&#123; listen 80; location ~ \\.php$ &#123; root html; fastcgi_pass 127.0.0.1:9000; #fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; &#125; &#125; 四、php-fpm配置配置文件路径etc/php-fpm.conf 简单配置下listen 127.0.0.1:9000 五、数据传递过程 www.example.com​ |​ |​ Nginx​ |​ |路由到www.example.com/index.php​ |​ |加载nginx的fast-cgi模块​ |​ |fast-cgi监听127.0.0.1:9000地址​ |​ |www.example.com/index.php请求到达127.0.0.1:9000​ |​ |php-fpm 监听127.0.0.1:9000​ |​ |php-fpm 接收到请求，启用worker进程处理请求​ |​ |php-fpm 处理完请求，返回给nginx​ |​ |nginx将结果通过http返回给浏览器​ 六、一些小纠结1、首先，CGI是干嘛的？CGI是为了保证web server传递过来的数据是标准格式的，方便CGI程序的编写者。 web server（比如说nginx）只是内容的分发者。比如，如果请求/index.html，那么web server会去文件系统中找到这个文件，发送给浏览器，这里分发的是静态数据。好了，如果现在请求的是/index.php，根据配置文件，nginx知道这个不是静态文件，需要去找PHP解析器来处理，那么他会把这个请求简单处理后交给PHP解析器。Nginx会传哪些数据给PHP解析器呢？url要有吧，查询字符串也得有吧，POST数据也要有，HTTP header不能少吧，好的，CGI就是规定要传哪些数据、以什么样的格式传递给后方处理这个请求的协议。仔细想想，你在PHP代码中使用的用户从哪里来的。 当web server收到/index.php这个请求后，会启动对应的CGI程序，这里就是PHP的解析器。接下来PHP解析器会解析php.ini文件，初始化执行环境，然后处理请求，再以规定CGI规定的格式返回处理后的结果，退出进程。web server再把结果返回给浏览器。 2、CGI是个协议，跟进程什么的没关系。那fastcgi又是什么呢？Fastcgi是用来提高CGI程序性能的。 提高性能，那么CGI程序的性能问题在哪呢？”PHP解析器会解析php.ini文件，初始化执行环境”，就是这里了。标准的CGI对每个请求都会执行这些步骤（不闲累啊！启动进程很累的说！），所以处理每个时间的时间会比较长。这明显不合理嘛！那么Fastcgi是怎么做的呢？首先，Fastcgi会先启一个master，解析配置文件，初始化执行环境，然后再启动多个worker。当请求过来时，master会传递给一个worker，然后立即可以接受下一个请求。这样就避免了重复的劳动，效率自然是高。而且当worker不够用时，master可以根据配置预先启动几个worker等着；当然空闲worker太多时，也会停掉一些，这样就提高了性能，也节约了资源。这就是fastcgi的对进程的管理。 3、那PHP-FPM又是什么呢？是一个实现了Fastcgi的程序，被PHP官方收了。 大家都知道，PHP的解释器是php-cgi。php-cgi只是个CGI程序，他自己本身只能解析请求，返回结果，不会进程管理（皇上，臣妾真的做不到啊！）所以就出现了一些能够调度php-cgi进程的程序，比如说由lighthttpd分离出来的spawn-fcgi。好了PHP-FPM也是这么个东东，在长时间的发展后，逐渐得到了大家的认可（要知道，前几年大家可是抱怨PHP-FPM稳定性太差的），也越来越流行。 Q: php-fpm是fastcgi进程的管理器，用来管理fastcgi进程的？？？ 对。php-fpm的管理对象是php-cgi。但不能说php-fpm是fastcgi进程的管理器，因为前面说了fastcgi是个协议，似乎没有这么个进程存在，就算存在php-fpm也管理不了他（至少目前是）。 有的说，php-fpm是php内核的一个补丁 以前是对的。因为最开始的时候php-fpm没有包含在PHP内核里面，要使用这个功能，需要找到与源码版本相同的php-fpm对内核打补丁，然后再编译。后来PHP内核集成了PHP-FPM之后就方便多了，使用--enalbe-fpm这个编译参数即可。 Q: 修改了php.ini配置文件后，没办法平滑重启，所以就诞生了php-fpm？？？ 是的，修改php.ini之后，php-cgi进程的确是没办法平滑重启的。php-fpm对此的处理机制是新的worker用新的配置，已经存在的worker处理完手上的活就可以歇着了，通过这种机制来平滑过度。 Q: 还有的说PHP-CGI是PHP自带的FastCGI管理器，那这样的话干吗又弄个php-fpm出？？？ 不对。php-cgi只是解释PHP脚本的程序而已。 在代理时如何保持请求头不变 By default, NGINX redefines two header fields in proxied requests, “Host” and “Connection”, and eliminates the header fields whose values are empty strings. “Host” is set to the $proxy_host variable, and “Connection” is set to close. location /some/path/ &#123; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_pass http://localhost:8000; &#125; 参考资料： https://segmentfault.com/a/1190000007322358 https://segmentfault.com/q/1010000000256516 https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/ https://blog.csdn.net/sunyuhua_keyboard/article/details/78273700","tags":[{"name":"Nginx","slug":"Nginx","permalink":"https://blog.yrpang.com/tags/Nginx/"}]},{"title":"Github","date":"2018-11-06T14:28:59.000Z","path":"posts/11118/","text":"Github 是什么？ gitHub是一个面向开源及私有软件项目的托管平台，因为只支持git 作为唯一的版本库格式进行托管，故名gitHub。 gitHub于2008年4月10日正式上线，除了git代码仓库托管及基本的 Web管理界面以外，还提供了订阅、讨论组、文本渲染、在线文件编辑器、协作图谱（报表）、代码片段分享（Gist）等功能。目前，其注册用户已经超过350万，托管版本数量也是非常之多，其中不乏知名开源项目 Ruby on Rails、jQuery、python 等。 简而言之，Github就是基于git的一个远程托管服务器。 Git基本操作新建本地库：创建新文件夹，执行git init 克隆远程仓库：git clone username@host:/path/to/repository 添加与提交： 在进行文件更改后，准备提交时，你应该先把它们添加到缓存区，使用：git add &lt;filename&gt;或者git add *这是 git 基本工作流程的第一步；使用命令：git commit -m &quot;代码提交信息&quot;，可以提交实际改动。完成以上两步后，你的改动已经提交到了 HEAD，但是还没到你的远端仓库。 将代码提交到远程库： 你的改动现在已经在本地仓库的 HEAD 中了，通过执行git push origin master你就可以把代码提交到远程库了。 P.S. 如果你还没有克隆现有仓库，并欲将你的仓库连接到某个远程服务器，你可以使用如下命令添加：git remote add origin &lt;server&gt; 更新与合并： 更新你的本地仓库至最新改动: git pull 在你的工作目录中 获取（fetch） 并 合并（merge） 远端的改动。要合并其他分支到你的当前分支（例如 master）git merge &lt;branch&gt; git 会尝试去自动合并改动。不幸的是，自动合并并非次次都能成功，并可能导致 冲突（conflicts） 。 这时候就需要你修改这些文件来人肉合并这些 冲突（conflicts） 了。改完之后，你需要执行如下命令以将它们标记为合并成功：git add &lt;filename&gt;在合并改动之前，也可以使用如下命令查看：git diff &lt;source_branch&gt; &lt;target_branch&gt; 一些概念工作流： 你的本地仓库由 git 维护的三棵“树”组成。第一个是你的 工作目录，它持有实际文件；第二个是 暂存区（Index），它像个缓存区域，临时保存你的改动；最后是 HEAD，它指向你最后一次提交的结果。 分支： 在你创建仓库的时候，master 是“默认的”。在其他分支上进行开发，完成后再将它们合并到主分支上。 e.g.: 创建一个叫做“feature_x”的分支，并切换过去：git checkout -b feature_x切换回主分支：git checkout master再把新建的分支删掉：git branch -d feature_x除非你将分支推送到远端仓库，不然该分支就是 不为他人所见的：git push origin &lt;branch&gt; 分支操作 查看分支git branch查看所有分支（本地和远程）git branch -a 删除本地分支git branch -d &lt;NAME&gt; 删除远程分支git push origin -d &lt;NAME&gt; 或者git branch -r -d origin/branch-name 删除追踪git push origin :&lt;NAME&gt; 删除远程分支 清理本地无效分支(远程已删除本地没删除的分支) git fetch -p 一些技巧使用时光机： 假如你做错事（自然，这是不可能的），你可以使用如下命令替换掉本地改动：git checkout -- &lt;filename&gt;此命令会使用 HEAD 中的最新内容替换掉你的工作目录中的文件。已添加到缓存区的改动，以及新文件，都不受影响。 假如你想要丢弃你所有的本地改动与提交，可以到服务器上获取最新的版本并将你本地主分支指向到它：git fetch origin git reset --hard origin/master 撤销文件修改 git ls-files -m | xargs git checkout --(过时) 撤销文件删除git ls-files -d | xargs git checkout -- 删除所有没有托管给git的文件git clean -d -xf 查看提交历史 # 每个提交在一行内显示 git log--oneline # 在所有提交日志中搜索包含「homepage」的提交 git log--all --grep=&#x27;homepage&#x27; # 获取某人的提交日志 git log--author=&quot;name&quot; 查看我的分支和master的不同 git diff master..my-branch 修改提交 # 编辑上次提交 git commit --amend -m &quot;更好的提交日志&quot; # 在上次提交中附加一些内容，保持提交日志不变git add . &amp;&amp; git commit --amend --no-edit # 空提交 —— 可以用来重新触发 CI 构建 git commit --allow-empty -m &quot;chore: re-trigger build&quot; 参考资料：git 高级用法小抄","tags":[{"name":"git","slug":"git","permalink":"https://blog.yrpang.com/tags/git/"}]},{"title":"hello-world","date":"2018-11-06T06:46:49.000Z","path":"posts/9408/","text":"一直想要专心写一些东西，却迟迟没能付诸实践，之前尝试用Wordpress建站，写来写去把好好的技术分享站写成了生活琐事流水账，违背了初心不说，最后也没坚持下来。 这次室友开了个人公众号，准备写点东西，我也跟着他的脚步，决定重新开博，索性放弃了繁杂臃肿的Wordpress 改用Hexo，简洁清晰，专心写内容。 感谢室友的支持，也感谢目前所用的这个主题的作者，也希望在不久的将来自己也可以写一个漂亮的主题出来。 最后贴一下室友的公众号，ZEROHA0，欢迎关注，多多支持。","tags":[]}]